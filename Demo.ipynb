{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorlayer as tl\n",
    "import tensorflow as tf\n",
    "from tensorlayer.layers import *\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(PATH='./'):\n",
    "    # read data control dictionaries\n",
    "    with open(PATH + 'metadata.pkl', 'rb') as f:\n",
    "        metadata = pickle.load(f)\n",
    "    # read numpy arrays\n",
    "    idx_q = np.load(PATH + 'idx_q.npy')\n",
    "    idx_a = np.load(PATH + 'idx_a.npy')\n",
    "    return metadata, idx_q, idx_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metadata, idx_q, idx_a = load_data(PATH='./') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "xvocab_size = len(metadata['idx2w']) # 8002 (0~8001)\n",
    "emb_dim = 1024\n",
    "\n",
    "w2idx = metadata['w2idx']   # dict  word 2 index\n",
    "idx2w = metadata['idx2w']   # list index 2 word\n",
    "\n",
    "unk_id = w2idx['unk']   # 1\n",
    "pad_id = w2idx['_']     # 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_id = xvocab_size  # 8002\n",
    "end_id = xvocab_size+1  # 8003\n",
    "\n",
    "w2idx.update({'start_id': start_id})\n",
    "w2idx.update({'end_id': end_id})\n",
    "idx2w = idx2w + ['start_id', 'end_id']\n",
    "\n",
    "xvocab_size = yvocab_size = xvocab_size + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(encode_seqs, decode_seqs, is_train=True, reuse=False):\n",
    "    with tf.variable_scope(\"model\", reuse=reuse):\n",
    "        # for chatbot, you can use the same embedding layer,\n",
    "        # for translation, you may want to use 2 seperated embedding layers\n",
    "        with tf.variable_scope(\"embedding\") as vs:\n",
    "            net_encode = EmbeddingInputlayer(\n",
    "                inputs = encode_seqs,\n",
    "                vocabulary_size = xvocab_size,\n",
    "                embedding_size = emb_dim,\n",
    "                name = 'seq_embedding')\n",
    "            vs.reuse_variables()\n",
    "#             tl.layers.set_name_reuse(True) # remove if TL version == 1.8.0+\n",
    "            net_decode = EmbeddingInputlayer(\n",
    "                inputs = decode_seqs,\n",
    "                vocabulary_size = xvocab_size,\n",
    "                embedding_size = emb_dim,\n",
    "                name = 'seq_embedding')\n",
    "        net_rnn = Seq2Seq(net_encode, net_decode,\n",
    "                cell_fn = tf.contrib.rnn.BasicLSTMCell,\n",
    "                n_hidden = emb_dim,\n",
    "                initializer = tf.random_uniform_initializer(-0.1, 0.1),\n",
    "                encode_sequence_length = retrieve_seq_length_op2(encode_seqs),\n",
    "                decode_sequence_length = retrieve_seq_length_op2(decode_seqs),\n",
    "                initial_state_encode = None,\n",
    "                dropout = (0.5 if is_train else None),\n",
    "                n_layer = 3,\n",
    "                return_seq_2d = True,\n",
    "                name = 'seq2seq')\n",
    "        net_out = DenseLayer(net_rnn, n_units=xvocab_size, act=tf.identity, name='output')\n",
    "    return net_out, net_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] EmbeddingInputlayer model/embedding/seq_embedding: (8004, 1024)\n",
      "[TL] EmbeddingInputlayer model/embedding/seq_embedding: (8004, 1024)\n",
      "[TL] [*] Seq2Seq model/seq2seq: n_hidden: 1024 cell_fn: BasicLSTMCell dropout: 0.5 n_layer: 3\n",
      "[TL] DynamicRNNLayer model/seq2seq/encode: n_hidden: 1024, in_dim: 3 in_shape: (32, ?, 1024) cell_fn: BasicLSTMCell dropout: 0.5 n_layer: 3\n",
      "[TL]        batch_size (concurrent processes): 32\n",
      "[TL] DynamicRNNLayer model/seq2seq/decode: n_hidden: 1024, in_dim: 3 in_shape: (32, ?, 1024) cell_fn: BasicLSTMCell dropout: 0.5 n_layer: 3\n",
      "[TL]        batch_size (concurrent processes): 32\n",
      "[TL] DenseLayer  model/output: 8004 No Activation\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    encode_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"encode_seqs\")\n",
    "    decode_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"decode_seqs\")\n",
    "    target_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"target_seqs\")\n",
    "    target_mask = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"target_mask\") # tl.prepro.sequences_get_mask()\n",
    "net_out, _ = model(encode_seqs, decode_seqs, is_train=True, reuse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] EmbeddingInputlayer model/embedding/seq_embedding: (8004, 1024)\n",
      "[TL] EmbeddingInputlayer model/embedding/seq_embedding: (8004, 1024)\n",
      "[TL] [*] Seq2Seq model/seq2seq: n_hidden: 1024 cell_fn: BasicLSTMCell dropout: None n_layer: 3\n",
      "[TL] DynamicRNNLayer model/seq2seq/encode: n_hidden: 1024, in_dim: 3 in_shape: (1, ?, 1024) cell_fn: BasicLSTMCell dropout: None n_layer: 3\n",
      "[TL]        batch_size (concurrent processes): 1\n",
      "[TL] DynamicRNNLayer model/seq2seq/decode: n_hidden: 1024, in_dim: 3 in_shape: (1, ?, 1024) cell_fn: BasicLSTMCell dropout: None n_layer: 3\n",
      "[TL]        batch_size (concurrent processes): 1\n",
      "[TL] DenseLayer  model/output: 8004 No Activation\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    encode_seqs2 = tf.placeholder(dtype=tf.int64, shape=[1, None], name=\"encode_seqs\")\n",
    "    decode_seqs2 = tf.placeholder(dtype=tf.int64, shape=[1, None], name=\"decode_seqs\")\n",
    "net, net_rnn = model(encode_seqs2, decode_seqs2, is_train=False, reuse=True)\n",
    "y = tf.nn.softmax(net.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] WARNING: From <ipython-input-9-61c494c905f4>:2: initialize_global_variables (from tensorlayer.layers.utils) is deprecated and will be removed after 2018-09-30.\n",
      "Instructions for updating: This API is deprecated in favor of `tf.global_variables_initializer`\n",
      "\n",
      "[TL] [*] Load n.npz SUCCESS!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorlayer.layers.dense.base_dense.DenseLayer at 0x7fcec936df60>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True))\n",
    "tl.layers.initialize_global_variables(sess)\n",
    "tl.files.load_and_assign_npz(sess=sess, name='n.npz', network=net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_me_bot(inputs=\"\"):\n",
    "    seed = inputs.lower()\n",
    "    seed_id = [w2idx[w] for w in seed.split(\" \")]\n",
    "    \n",
    "    state = sess.run(net_rnn.final_state_encode,\n",
    "                                    {encode_seqs2: [seed_id]})\n",
    "    o, state = sess.run([y, net_rnn.final_state_decode],\n",
    "                                        {net_rnn.initial_state_decode: state,\n",
    "                                        decode_seqs2: [[start_id]]})\n",
    "    w_id = tl.nlp.sample_top(o[0], top_k=3)\n",
    "    w = idx2w[w_id]\n",
    "    # 3. decode, feed state iteratively\n",
    "    sentence = [w]\n",
    "    for _ in range(30): # max sentence length\n",
    "        o, state = sess.run([y, net_rnn.final_state_decode],\n",
    "                            {net_rnn.initial_state_decode: state,\n",
    "                            decode_seqs2: [[w_id]]})\n",
    "        w_id = tl.nlp.sample_top(o[0], top_k=2)\n",
    "        w = idx2w[w_id]\n",
    "        if w_id == end_id:\n",
    "            break\n",
    "        sentence = sentence + [w]\n",
    "    print(\" >\", ' '.join(sentence))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > i want you to tell me what you said\n"
     ]
    }
   ],
   "source": [
    "answer_me_bot(\"test me\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
