{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorlayer as tl\n",
    "import tensorflow as tf\n",
    "from tensorlayer.layers import *\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "xvocab_size = 40004\n",
    "emb_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_TOKEN = 0\n",
    "glove_data_directory = '.'\n",
    "\n",
    "word2idx = { 'PAD': PAD_TOKEN } # dict so we can lookup indices for tokenising our text later from string to sequence of integers\n",
    "weights = []\n",
    "\n",
    "with open (glove_data_directory + '/' +'glove.6B.100d.txt', 'r') as file:\n",
    "    for index, line in enumerate(file):\n",
    "        values = line.split() # Word and weights separated by space\n",
    "        word = values[0] # Word is first symbol on each line\n",
    "        word_weights = np.asarray(values[1:], dtype=np.float32) # Remainder of line is weights for word\n",
    "        word2idx[word] = index + 1 # PAD is our zeroth index so shift by one\n",
    "        weights.append(word_weights)\n",
    "        \n",
    "        if index + 1 == 40_000:\n",
    "            # Limit vocabulary to top 40k terms\n",
    "            break\n",
    "\n",
    "EMBEDDING_DIMENSION = len(weights[0])\n",
    "# Insert the PAD weights at index 0 now we know the embedding dimension\n",
    "weights.insert(0, np.random.randn(EMBEDDING_DIMENSION))\n",
    "\n",
    "# Append unknown and pad to end of vocab and initialize as random\n",
    "UNKNOWN_TOKEN=len(weights)\n",
    "word2idx['UNK'] = UNKNOWN_TOKEN\n",
    "weights.append(np.random.randn(EMBEDDING_DIMENSION))\n",
    "\n",
    "\n",
    "# Construct our final vocab\n",
    "weights = np.asarray(weights, dtype=np.float32)\n",
    "\n",
    "VOCAB_SIZE=weights.shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = list(word2idx.keys())\n",
    "VOCAB_LENGTH = len(word2idx)\n",
    "\n",
    "\n",
    "unk_id = word2idx['UNK']   \n",
    "pad_id = word2idx['PAD']     \n",
    "\n",
    "start_id = VOCAB_LENGTH \n",
    "end_id = VOCAB_LENGTH + 1\n",
    "\n",
    "word2idx.update({'start_id': start_id})\n",
    "word2idx.update({'end_id': end_id})\n",
    "idx2word = idx2word + ['start_id', 'end_id']\n",
    "xvocab_size = len(idx2word)\n",
    "\n",
    "\n",
    "VOCAB_LENGTH = VOCAB_LENGTH + 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(encode_seqs, decode_seqs, is_train=True, reuse=False):\n",
    "    with tf.variable_scope(\"model\", reuse=reuse):\n",
    "        # for chatbot, you can use the same embedding layer,\n",
    "        # for translation, you may want to use 2 seperated embedding layers\n",
    "        with tf.variable_scope(\"embedding\") as vs:\n",
    "            net_encode = EmbeddingInputlayer(\n",
    "                inputs = encode_seqs,\n",
    "                vocabulary_size = xvocab_size,\n",
    "                embedding_size = emb_dim,\n",
    "                name = 'seq_embedding')\n",
    "            vs.reuse_variables()\n",
    "#             tl.layers.set_name_reuse(True) # remove if TL version == 1.8.0+\n",
    "            net_decode = EmbeddingInputlayer(\n",
    "                inputs = decode_seqs,\n",
    "                vocabulary_size = xvocab_size,\n",
    "                embedding_size = emb_dim,\n",
    "                name = 'seq_embedding')\n",
    "        net_rnn = Seq2Seq(net_encode, net_decode,\n",
    "                cell_fn = tf.contrib.rnn.BasicLSTMCell,\n",
    "                n_hidden = emb_dim,\n",
    "                initializer = tf.random_uniform_initializer(-0.1, 0.1),\n",
    "                encode_sequence_length = retrieve_seq_length_op2(encode_seqs),\n",
    "                decode_sequence_length = retrieve_seq_length_op2(decode_seqs),\n",
    "                initial_state_encode = None,\n",
    "                dropout = (0.5 if is_train else None),\n",
    "                n_layer = 3,\n",
    "                return_seq_2d = True,\n",
    "                name = 'seq2seq')\n",
    "        net_out = DenseLayer(net_rnn, n_units=xvocab_size, act=tf.identity, name='output')\n",
    "    return net_out, net_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] EmbeddingInputlayer model/embedding/seq_embedding: (40004, 100)\n",
      "[TL] EmbeddingInputlayer model/embedding/seq_embedding: (40004, 100)\n",
      "[TL] [*] Seq2Seq model/seq2seq: n_hidden: 100 cell_fn: BasicLSTMCell dropout: 0.5 n_layer: 3\n",
      "[TL] DynamicRNNLayer model/seq2seq/encode: n_hidden: 100, in_dim: 3 in_shape: (32, ?, 100) cell_fn: BasicLSTMCell dropout: 0.5 n_layer: 3\n",
      "[TL]        batch_size (concurrent processes): 32\n",
      "[TL] DynamicRNNLayer model/seq2seq/decode: n_hidden: 100, in_dim: 3 in_shape: (32, ?, 100) cell_fn: BasicLSTMCell dropout: 0.5 n_layer: 3\n",
      "[TL]        batch_size (concurrent processes): 32\n",
      "[TL] DenseLayer  model/output: 40004 No Activation\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    encode_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"encode_seqs\")\n",
    "    decode_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"decode_seqs\")\n",
    "    target_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"target_seqs\")\n",
    "    target_mask = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"target_mask\") # tl.prepro.sequences_get_mask()\n",
    "net_out, _ = model(encode_seqs, decode_seqs, is_train=True, reuse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] EmbeddingInputlayer model/embedding/seq_embedding: (40004, 100)\n",
      "[TL] EmbeddingInputlayer model/embedding/seq_embedding: (40004, 100)\n",
      "[TL] [*] Seq2Seq model/seq2seq: n_hidden: 100 cell_fn: BasicLSTMCell dropout: None n_layer: 3\n",
      "[TL] DynamicRNNLayer model/seq2seq/encode: n_hidden: 100, in_dim: 3 in_shape: (1, ?, 100) cell_fn: BasicLSTMCell dropout: None n_layer: 3\n",
      "[TL]        batch_size (concurrent processes): 1\n",
      "[TL] DynamicRNNLayer model/seq2seq/decode: n_hidden: 100, in_dim: 3 in_shape: (1, ?, 100) cell_fn: BasicLSTMCell dropout: None n_layer: 3\n",
      "[TL]        batch_size (concurrent processes): 1\n",
      "[TL] DenseLayer  model/output: 40004 No Activation\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    encode_seqs2 = tf.placeholder(dtype=tf.int64, shape=[1, None], name=\"encode_seqs\")\n",
    "    decode_seqs2 = tf.placeholder(dtype=tf.int64, shape=[1, None], name=\"decode_seqs\")\n",
    "net, net_rnn = model(encode_seqs2, decode_seqs2, is_train=False, reuse=True)\n",
    "y = tf.nn.softmax(net.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] WARNING: From <ipython-input-8-fca9baf3d625>:2: initialize_global_variables (from tensorlayer.layers.utils) is deprecated and will be removed after 2018-09-30.\n",
      "Instructions for updating: This API is deprecated in favor of `tf.global_variables_initializer`\n",
      "\n",
      "[TL] [*] Load n2.npz SUCCESS!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorlayer.layers.dense.base_dense.DenseLayer at 0x7f3020369eb8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True))\n",
    "tl.layers.initialize_global_variables(sess)\n",
    "tl.files.load_and_assign_npz(sess=sess, name='n2.npz', network=net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_me_bot(inputs=\"\"):\n",
    "    seed = inputs\n",
    "    seed_id = [word2idx[w] for w in seed.split(\" \")]\n",
    "    state = sess.run(net_rnn.final_state_encode,\n",
    "                                    {encode_seqs2: [seed_id]})\n",
    "    o, state = sess.run([y, net_rnn.final_state_decode],\n",
    "                                        {net_rnn.initial_state_decode: state,\n",
    "                                        decode_seqs2: [[start_id]]})\n",
    "    w_id = tl.nlp.sample_top(o[0], top_k=3)\n",
    "    w = idx2word[w_id]\n",
    "    # 3. decode, feed state iteratively\n",
    "    sentence = [w]\n",
    "    for _ in range(30): # max sentence length\n",
    "        o, state = sess.run([y, net_rnn.final_state_decode],\n",
    "                            {net_rnn.initial_state_decode: state,\n",
    "                            decode_seqs2: [[w_id]]})\n",
    "        w_id = tl.nlp.sample_top(o[0], top_k=2)\n",
    "        w = idx2word[w_id]\n",
    "        if w_id == end_id:\n",
    "            break\n",
    "        sentence = sentence + [w]\n",
    "    print(\" >\", ' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > yes .\n"
     ]
    }
   ],
   "source": [
    "answer_me_bot(\"you are such a boring guy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
