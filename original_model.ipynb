{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Declaration**: Most code of this work is from https://github.com/tensorlayer/seq2seq-chatbot. I changed some of data processing code and modified the model in order to make it work on my laptop. An important goal of this final project is to compare the impacts of pretrained embedding and trained-from-scratch embedding to the results. My work is mainly focused on introducing the GloVe embedding matrix, in which I have to modify the code from data prepratation and totally rewrite the embedding layer part of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import nltk\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EN_WHITELIST = '0123456789abcdefghijklmnopqrstuvwxyz ' # space is included in whitelist\n",
    "EN_BLACKLIST = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~\\''\n",
    "limit = {'maxq' : 25, 'minq' : 2, 'maxa' : 25, 'mina' : 2}\n",
    "UNK = 'unk'\n",
    "VOCAB_SIZE = 8000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id2line():\n",
    "    lines=open('/home/ubuntu/nlp_data/movie_lines.txt', encoding='utf-8', errors='ignore').read().split('\\n')\n",
    "    id2line = {}\n",
    "    for line in lines:\n",
    "        _line = line.split(' +++$+++ ')\n",
    "        if len(_line) == 5:\n",
    "            id2line[_line[0]] = _line[4]\n",
    "    return id2line\n",
    "\n",
    "def get_conversations():\n",
    "    conv_lines = open('/home/ubuntu/nlp_data/movie_conversations.txt', encoding='utf-8', errors='ignore').read().split('\\n')\n",
    "    convs = [ ]\n",
    "    for line in conv_lines[:-1]:\n",
    "        _line = line.split(' +++$+++ ')[-1][1:-1].replace(\"'\",\"\").replace(\" \",\"\")\n",
    "        convs.append(_line.split(','))\n",
    "    return convs\n",
    "\n",
    "def extract_conversations(convs,id2line,path=''):\n",
    "    idx = 0\n",
    "    for conv in convs:\n",
    "        f_conv = open(path + str(idx)+'.txt', 'w')\n",
    "        for line_id in conv:\n",
    "            f_conv.write(id2line[line_id])\n",
    "            f_conv.write('\\n')\n",
    "        f_conv.close()\n",
    "        idx += 1\n",
    "        \n",
    "def gather_dataset(convs, id2line):\n",
    "    questions = []; answers = []\n",
    "    for conv in convs:\n",
    "        if len(conv) %2 != 0:\n",
    "            conv = conv[:-1]\n",
    "        for i in range(len(conv)):\n",
    "            if i%2 == 0:\n",
    "                questions.append(id2line[conv[i]])\n",
    "            else:\n",
    "                answers.append(id2line[conv[i]])\n",
    "\n",
    "    return questions, answers\n",
    "\n",
    "def prepare_seq2seq_files(questions, answers, path='',TESTSET_SIZE = 30000):\n",
    "\n",
    "    # open files\n",
    "    train_enc = open(path + 'train.enc','w')\n",
    "    train_dec = open(path + 'train.dec','w')\n",
    "    test_enc  = open(path + 'test.enc', 'w')\n",
    "    test_dec  = open(path + 'test.dec', 'w')\n",
    "\n",
    "    # choose 30,000 (TESTSET_SIZE) items to put into testset\n",
    "    test_ids = random.sample([i for i in range(len(questions))],TESTSET_SIZE)\n",
    "\n",
    "    for i in range(len(questions)):\n",
    "        if i in test_ids:\n",
    "            test_enc.write(questions[i]+'\\n')\n",
    "            test_dec.write(answers[i]+ '\\n' )\n",
    "        else:\n",
    "            train_enc.write(questions[i]+'\\n')\n",
    "            train_dec.write(answers[i]+ '\\n' )\n",
    "        if i%10000 == 0:\n",
    "            print('\\n>> written {} lines'.format(i))\n",
    "\n",
    "    # close files\n",
    "    train_enc.close()\n",
    "    train_dec.close()\n",
    "    test_enc.close()\n",
    "    test_dec.close()\n",
    "\n",
    "\n",
    "def filter_line(line, whitelist):\n",
    "    return ''.join([ ch for ch in line if ch in whitelist ])\n",
    "\n",
    "def filter_data(qseq, aseq):\n",
    "    filtered_q, filtered_a = [], []\n",
    "    raw_data_len = len(qseq)\n",
    "\n",
    "    assert len(qseq) == len(aseq)\n",
    "\n",
    "    for i in range(raw_data_len):\n",
    "        qlen, alen = len(qseq[i].split(' ')), len(aseq[i].split(' '))\n",
    "        if qlen >= limit['minq'] and qlen <= limit['maxq']:\n",
    "            if alen >= limit['mina'] and alen <= limit['maxa']:\n",
    "                filtered_q.append(qseq[i])\n",
    "                filtered_a.append(aseq[i])\n",
    "\n",
    "    # print the fraction of the original data, filtered\n",
    "    filt_data_len = len(filtered_q)\n",
    "    filtered = int((raw_data_len - filt_data_len)*100/raw_data_len)\n",
    "    print(str(filtered) + '% filtered from original data')\n",
    "\n",
    "    return filtered_q, filtered_a\n",
    "\n",
    "'''\n",
    " read list of words, create index to word,\n",
    "  word to index dictionaries\n",
    "    return tuple( vocab->(word, count), idx2w, w2idx )\n",
    "'''\n",
    "def index_(tokenized_sentences, vocab_size):\n",
    "    # get frequency distribution\n",
    "    freq_dist = nltk.FreqDist(itertools.chain(*tokenized_sentences))\n",
    "    # get vocabulary of 'vocab_size' most used words\n",
    "    vocab = freq_dist.most_common(vocab_size)\n",
    "    # index2word\n",
    "    index2word = ['_'] + [UNK] + [ x[0] for x in vocab ]\n",
    "    # word2index\n",
    "    word2index = dict([(w,i) for i,w in enumerate(index2word)] )\n",
    "    return index2word, word2index, freq_dist\n",
    "\n",
    "'''\n",
    " filter based on number of unknowns (words not in vocabulary)\n",
    "  filter out the worst sentences\n",
    "'''\n",
    "def filter_unk(qtokenized, atokenized, w2idx):\n",
    "    data_len = len(qtokenized)\n",
    "\n",
    "    filtered_q, filtered_a = [], []\n",
    "\n",
    "    for qline, aline in zip(qtokenized, atokenized):\n",
    "        unk_count_q = len([ w for w in qline if w not in w2idx ])\n",
    "        unk_count_a = len([ w for w in aline if w not in w2idx ])\n",
    "        if unk_count_a <= 2:\n",
    "            if unk_count_q > 0:\n",
    "                if unk_count_q/len(qline) > 0.2:\n",
    "                    pass\n",
    "            filtered_q.append(qline)\n",
    "            filtered_a.append(aline)\n",
    "\n",
    "    # print the fraction of the original data, filtered\n",
    "    filt_data_len = len(filtered_q)\n",
    "    filtered = int((data_len - filt_data_len)*100/data_len)\n",
    "    print(str(filtered) + '% filtered from original data')\n",
    "\n",
    "    return filtered_q, filtered_a\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    " create the final dataset :\n",
    "  - convert list of items to arrays of indices\n",
    "  - add zero padding\n",
    "      return ( [array_en([indices]), array_ta([indices]) )\n",
    "'''\n",
    "def zero_pad(qtokenized, atokenized, w2idx):\n",
    "    # num of rows\n",
    "    data_len = len(qtokenized)\n",
    "\n",
    "    # numpy arrays to store indices\n",
    "    idx_q = np.zeros([data_len, limit['maxq']], dtype=np.int32)\n",
    "    idx_a = np.zeros([data_len, limit['maxa']], dtype=np.int32)\n",
    "\n",
    "    for i in range(data_len):\n",
    "        q_indices = pad_seq(qtokenized[i], w2idx, limit['maxq'])\n",
    "        a_indices = pad_seq(atokenized[i], w2idx, limit['maxa'])\n",
    "\n",
    "        #print(len(idx_q[i]), len(q_indices))\n",
    "        #print(len(idx_a[i]), len(a_indices))\n",
    "        idx_q[i] = np.array(q_indices)\n",
    "        idx_a[i] = np.array(a_indices)\n",
    "\n",
    "    return idx_q, idx_a\n",
    "\n",
    "\n",
    "'''\n",
    " replace words with indices in a sequence\n",
    "  replace with unknown if word not in lookup\n",
    "    return [list of indices]\n",
    "'''\n",
    "def pad_seq(seq, lookup, maxlen):\n",
    "    indices = []\n",
    "    for word in seq:\n",
    "        if word in lookup:\n",
    "            indices.append(lookup[word])\n",
    "        else:\n",
    "            indices.append(lookup[UNK])\n",
    "    return indices + [0]*(maxlen - len(seq))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def process_data():\n",
    "\n",
    "    id2line = get_id2line()\n",
    "    print('>> gathered id2line dictionary.\\n')\n",
    "    convs = get_conversations()\n",
    "    print(convs[121:125])\n",
    "    print('>> gathered conversations.\\n')\n",
    "    questions, answers = gather_dataset(convs,id2line)\n",
    "\n",
    "    # change to lower case (just for en)\n",
    "    questions = [ line.lower() for line in questions ]\n",
    "    answers = [ line.lower() for line in answers ]\n",
    "\n",
    "    # filter out unnecessary characters\n",
    "    print('\\n>> Filter lines')\n",
    "    questions = [ filter_line(line, EN_WHITELIST) for line in questions ]\n",
    "    answers = [ filter_line(line, EN_WHITELIST) for line in answers ]\n",
    "\n",
    "    # filter out too long or too short sequences\n",
    "    print('\\n>> 2nd layer of filtering')\n",
    "    qlines, alines = filter_data(questions, answers)\n",
    "\n",
    "    for q,a in zip(qlines[141:145], alines[141:145]):\n",
    "        print('q : [{0}]; a : [{1}]'.format(q,a))\n",
    "\n",
    "    # convert list of [lines of text] into list of [list of words ]\n",
    "    print('\\n>> Segment lines into words')\n",
    "    qtokenized = [ [w.strip() for w in wordlist.split(' ') if w] for wordlist in qlines ]\n",
    "    atokenized = [ [w.strip() for w in wordlist.split(' ') if w] for wordlist in alines ]\n",
    "    print('\\n:: Sample from segmented list of words')\n",
    "\n",
    "    for q,a in zip(qtokenized[141:145], atokenized[141:145]):\n",
    "        print('q : [{0}]; a : [{1}]'.format(q,a))\n",
    "\n",
    "    # indexing -> idx2w, w2idx\n",
    "    print('\\n >> Index words')\n",
    "    idx2w, w2idx, freq_dist = index_( qtokenized + atokenized, vocab_size=VOCAB_SIZE)\n",
    "\n",
    "    # filter out sentences with too many unknowns\n",
    "    print('\\n >> Filter Unknowns')\n",
    "    qtokenized, atokenized = filter_unk(qtokenized, atokenized, w2idx)\n",
    "    print('\\n Final dataset len : ' + str(len(qtokenized)))\n",
    "\n",
    "\n",
    "    print('\\n >> Zero Padding')\n",
    "    idx_q, idx_a = zero_pad(qtokenized, atokenized, w2idx)\n",
    "\n",
    "    print('\\n >> Save numpy arrays to disk')\n",
    "    # save them\n",
    "    np.save('idx_q.npy', idx_q)\n",
    "    np.save('idx_a.npy', idx_a)\n",
    "\n",
    "    # let us now save the necessary dictionaries\n",
    "    metadata = {\n",
    "            'w2idx' : w2idx,\n",
    "            'idx2w' : idx2w,\n",
    "            'limit' : limit,\n",
    "            'freq_dist' : freq_dist\n",
    "                }\n",
    "\n",
    "    # write to disk : data control dictionaries\n",
    "    with open('metadata.pkl', 'wb') as f:\n",
    "        pickle.dump(metadata, f)\n",
    "\n",
    "    # count of unknowns\n",
    "    unk_count = (idx_q == 1).sum() + (idx_a == 1).sum()\n",
    "    # count of words\n",
    "    word_count = (idx_q > 1).sum() + (idx_a > 1).sum()\n",
    "\n",
    "    print('% unknown : {0}'.format(100 * (unk_count/word_count)))\n",
    "    print('Dataset count : ' + str(idx_q.shape[0]))\n",
    "\n",
    "\n",
    "    #print '>> gathered questions and answers.\\n'\n",
    "    #prepare_seq2seq_files(questions,answers)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from random import sample\n",
    "\n",
    "'''\n",
    " split data into train (70%), test (15%) and valid(15%)\n",
    "    return tuple( (trainX, trainY), (testX,testY), (validX,validY) )\n",
    "'''\n",
    "def split_dataset(x, y, ratio = [0.7, 0.15, 0.15] ):\n",
    "    # number of examples\n",
    "    data_len = len(x)\n",
    "    lens = [ int(data_len*item) for item in ratio ]\n",
    "\n",
    "    trainX, trainY = x[:lens[0]], y[:lens[0]]\n",
    "    testX, testY = x[lens[0]:lens[0]+lens[1]], y[lens[0]:lens[0]+lens[1]]\n",
    "    validX, validY = x[-lens[-1]:], y[-lens[-1]:]\n",
    "\n",
    "    return (trainX,trainY), (testX,testY), (validX,validY)\n",
    "\n",
    "\n",
    "'''\n",
    " generate batches from dataset\n",
    "    yield (x_gen, y_gen)\n",
    "    TODO : fix needed\n",
    "'''\n",
    "def batch_gen(x, y, batch_size):\n",
    "    # infinite while\n",
    "    while True:\n",
    "        for i in range(0, len(x), batch_size):\n",
    "            if (i+1)*batch_size < len(x):\n",
    "                yield x[i : (i+1)*batch_size ].T, y[i : (i+1)*batch_size ].T\n",
    "\n",
    "'''\n",
    " generate batches, by random sampling a bunch of items\n",
    "    yield (x_gen, y_gen)\n",
    "'''\n",
    "def rand_batch_gen(x, y, batch_size):\n",
    "    while True:\n",
    "        sample_idx = sample(list(np.arange(len(x))), batch_size)\n",
    "        yield x[sample_idx].T, y[sample_idx].T\n",
    "\n",
    "        \n",
    "def decode(sequence, lookup, separator=''): # 0 used for padding, is ignored\n",
    "    return separator.join([ lookup[element] for element in sequence if element ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_data(PATH=''):\n",
    "    # read data control dictionaries\n",
    "    with open(PATH + 'metadata.pkl', 'rb') as f:\n",
    "        metadata = pickle.load(f)\n",
    "    # read numpy arrays\n",
    "    idx_q = np.load(PATH + 'idx_q.npy')\n",
    "    idx_a = np.load(PATH + 'idx_a.npy')\n",
    "    return metadata, idx_q, idx_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> gathered id2line dictionary.\n",
      "\n",
      "[['L447', 'L448'], ['L490', 'L491'], ['L716', 'L717', 'L718', 'L719', 'L720', 'L721'], ['L750', 'L751', 'L752', 'L753', 'L754', 'L755']]\n",
      ">> gathered conversations.\n",
      "\n",
      "\n",
      ">> Filter lines\n",
      "\n",
      ">> 2nd layer of filtering\n",
      "28% filtered from original data\n",
      "q : [you hate me dont you]; a : [i dont really think you warrant that strong an emotion]\n",
      "q : [then say youll spend dollar night at the track with me]; a : [and why would i do that]\n",
      "q : [come on  the ponies the flat beer you with money in your eyes me with my hand on your ass]; a : [you  covered in my vomit]\n",
      "q : [are you following me]; a : [i was in the laundromat i saw your car thought id say hi]\n",
      "\n",
      ">> Segment lines into words\n",
      "\n",
      ":: Sample from segmented list of words\n",
      "q : [['you', 'hate', 'me', 'dont', 'you']]; a : [['i', 'dont', 'really', 'think', 'you', 'warrant', 'that', 'strong', 'an', 'emotion']]\n",
      "q : [['then', 'say', 'youll', 'spend', 'dollar', 'night', 'at', 'the', 'track', 'with', 'me']]; a : [['and', 'why', 'would', 'i', 'do', 'that']]\n",
      "q : [['come', 'on', 'the', 'ponies', 'the', 'flat', 'beer', 'you', 'with', 'money', 'in', 'your', 'eyes', 'me', 'with', 'my', 'hand', 'on', 'your', 'ass']]; a : [['you', 'covered', 'in', 'my', 'vomit']]\n",
      "q : [['are', 'you', 'following', 'me']]; a : [['i', 'was', 'in', 'the', 'laundromat', 'i', 'saw', 'your', 'car', 'thought', 'id', 'say', 'hi']]\n",
      "\n",
      " >> Index words\n",
      "\n",
      " >> Filter Unknowns\n",
      "2% filtered from original data\n",
      "\n",
      " Final dataset len : 96473\n",
      "\n",
      " >> Zero Padding\n",
      "\n",
      " >> Save numpy arrays to disk\n",
      "% unknown : 4.27073242918805\n",
      "Dataset count : 96473\n"
     ]
    }
   ],
   "source": [
    "process_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2seq Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encode_seqs ['you', 'know', 'unk']\n",
      "target_seqs ['i', 'believe', 'we', 'share', 'an', 'art', 'unk', 'end_id']\n",
      "decode_seqs ['start_id', 'i', 'believe', 'we', 'share', 'an', 'art', 'unk']\n",
      "target_mask [1 1 1 1 1 1 1 1]\n",
      "8 8 8\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorlayer as tl\n",
    "from tensorlayer.layers import *\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "###============= prepare data\n",
    "# from data.twitter import data\n",
    "# metadata, idx_q, idx_a = data.load_data(PATH='data/twitter/')                   # Twitter\n",
    "# from data.cornell_corpus import data\n",
    "metadata, idx_q, idx_a = load_data(PATH='./')          # Cornell Moive\n",
    "(trainX, trainY), (testX, testY), (validX, validY) = split_dataset(idx_q, idx_a)\n",
    "\n",
    "trainX = trainX.tolist()\n",
    "trainY = trainY.tolist()\n",
    "testX = testX.tolist()\n",
    "testY = testY.tolist()\n",
    "validX = validX.tolist()\n",
    "validY = validY.tolist()\n",
    "\n",
    "trainX = tl.prepro.remove_pad_sequences(trainX)\n",
    "trainY = tl.prepro.remove_pad_sequences(trainY)\n",
    "testX = tl.prepro.remove_pad_sequences(testX)\n",
    "testY = tl.prepro.remove_pad_sequences(testY)\n",
    "validX = tl.prepro.remove_pad_sequences(validX)\n",
    "validY = tl.prepro.remove_pad_sequences(validY)\n",
    "\n",
    "###============= parameters\n",
    "xseq_len = len(trainX)#.shape[-1]\n",
    "yseq_len = len(trainY)#.shape[-1]\n",
    "assert xseq_len == yseq_len\n",
    "batch_size = 32\n",
    "n_step = int(xseq_len/batch_size)\n",
    "xvocab_size = len(metadata['idx2w']) # 8002 (0~8001)\n",
    "emb_dim = 1024\n",
    "\n",
    "w2idx = metadata['w2idx']   # dict  word 2 index\n",
    "idx2w = metadata['idx2w']   # list index 2 word\n",
    "\n",
    "unk_id = w2idx['unk']   # 1\n",
    "pad_id = w2idx['_']     # 0\n",
    "\n",
    "start_id = xvocab_size  # 8002\n",
    "end_id = xvocab_size+1  # 8003\n",
    "\n",
    "w2idx.update({'start_id': start_id})\n",
    "w2idx.update({'end_id': end_id})\n",
    "idx2w = idx2w + ['start_id', 'end_id']\n",
    "\n",
    "xvocab_size = yvocab_size = xvocab_size + 2\n",
    "\n",
    "\"\"\" A data for Seq2Seq should look like this:\n",
    "input_seqs : ['how', 'are', 'you', '<PAD_ID'>]\n",
    "decode_seqs : ['<START_ID>', 'I', 'am', 'fine', '<PAD_ID'>]\n",
    "target_seqs : ['I', 'am', 'fine', '<END_ID>', '<PAD_ID'>]\n",
    "target_mask : [1, 1, 1, 1, 0]\n",
    "\"\"\"\n",
    "\n",
    "print(\"encode_seqs\", [idx2w[id] for id in trainX[10]])\n",
    "target_seqs = tl.prepro.sequences_add_end_id([trainY[10]], end_id=end_id)[0]\n",
    "    # target_seqs = tl.prepro.remove_pad_sequences([target_seqs], pad_id=pad_id)[0]\n",
    "print(\"target_seqs\", [idx2w[id] for id in target_seqs])\n",
    "decode_seqs = tl.prepro.sequences_add_start_id([trainY[10]], start_id=start_id, remove_last=False)[0]\n",
    "    # decode_seqs = tl.prepro.remove_pad_sequences([decode_seqs], pad_id=pad_id)[0]\n",
    "print(\"decode_seqs\", [idx2w[id] for id in decode_seqs])\n",
    "target_mask = tl.prepro.sequences_get_mask([target_seqs])[0]\n",
    "print(\"target_mask\", target_mask)\n",
    "print(len(target_seqs), len(decode_seqs), len(target_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encode_seqs ['you', 'know', 'unk']\n",
      "target_seqs ['i', 'believe', 'we', 'share', 'an', 'art', 'unk', 'end_id']\n",
      "decode_seqs ['start_id', 'i', 'believe', 'we', 'share', 'an', 'art', 'unk']\n",
      "target_mask [1 1 1 1 1 1 1 1]\n",
      "8 8 8\n",
      "[TL] EmbeddingInputlayer model/embedding/seq_embedding: (8004, 1024)\n",
      "[TL] WARNING: From <ipython-input-15-a61d1b7a1d3e>:84: set_name_reuse (from tensorlayer.layers.utils) is deprecated and will be removed after 2018-06-30.\n",
      "Instructions for updating: TensorLayer relies on TensorFlow to check name reusing\n",
      "\n",
      "[TL] WARNING: this method is DEPRECATED and has no effect, please remove it from your code.\n",
      "[TL] EmbeddingInputlayer model/embedding/seq_embedding: (8004, 1024)\n",
      "[TL] [*] Seq2Seq model/seq2seq: n_hidden: 1024 cell_fn: BasicLSTMCell dropout: 0.5 n_layer: 3\n",
      "[TL] DynamicRNNLayer model/seq2seq/encode: n_hidden: 1024, in_dim: 3 in_shape: (32, ?, 1024) cell_fn: BasicLSTMCell dropout: 0.5 n_layer: 3\n",
      "[TL]        batch_size (concurrent processes): 32\n",
      "[TL] DynamicRNNLayer model/seq2seq/decode: n_hidden: 1024, in_dim: 3 in_shape: (32, ?, 1024) cell_fn: BasicLSTMCell dropout: 0.5 n_layer: 3\n",
      "[TL]        batch_size (concurrent processes): 32\n",
      "[TL] DenseLayer  model/output: 8004 No Activation\n",
      "[TL] EmbeddingInputlayer model/embedding/seq_embedding: (8004, 1024)\n",
      "[TL] WARNING: this method is DEPRECATED and has no effect, please remove it from your code.\n",
      "[TL] EmbeddingInputlayer model/embedding/seq_embedding: (8004, 1024)\n",
      "[TL] [*] Seq2Seq model/seq2seq: n_hidden: 1024 cell_fn: BasicLSTMCell dropout: None n_layer: 3\n",
      "[TL] DynamicRNNLayer model/seq2seq/encode: n_hidden: 1024, in_dim: 3 in_shape: (1, ?, 1024) cell_fn: BasicLSTMCell dropout: None n_layer: 3\n",
      "[TL]        batch_size (concurrent processes): 1\n",
      "[TL] DynamicRNNLayer model/seq2seq/decode: n_hidden: 1024, in_dim: 3 in_shape: (1, ?, 1024) cell_fn: BasicLSTMCell dropout: None n_layer: 3\n",
      "[TL]        batch_size (concurrent processes): 1\n",
      "[TL] DenseLayer  model/output: 8004 No Activation\n",
      "[TL]   param   0: model/embedding/seq_embedding/embeddings:0 (8004, 1024)       float32_ref\n",
      "[TL]   param   1: model/seq2seq/encode/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0 (2048, 4096)       float32_ref\n",
      "[TL]   param   2: model/seq2seq/encode/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0 (4096,)            float32_ref\n",
      "[TL]   param   3: model/seq2seq/encode/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0 (2048, 4096)       float32_ref\n",
      "[TL]   param   4: model/seq2seq/encode/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0 (4096,)            float32_ref\n",
      "[TL]   param   5: model/seq2seq/encode/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/kernel:0 (2048, 4096)       float32_ref\n",
      "[TL]   param   6: model/seq2seq/encode/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/bias:0 (4096,)            float32_ref\n",
      "[TL]   param   7: model/seq2seq/decode/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/kernel:0 (2048, 4096)       float32_ref\n",
      "[TL]   param   8: model/seq2seq/decode/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/bias:0 (4096,)            float32_ref\n",
      "[TL]   param   9: model/seq2seq/decode/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/kernel:0 (2048, 4096)       float32_ref\n",
      "[TL]   param  10: model/seq2seq/decode/rnn/multi_rnn_cell/cell_1/basic_lstm_cell/bias:0 (4096,)            float32_ref\n",
      "[TL]   param  11: model/seq2seq/decode/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/kernel:0 (2048, 4096)       float32_ref\n",
      "[TL]   param  12: model/seq2seq/decode/rnn/multi_rnn_cell/cell_2/basic_lstm_cell/bias:0 (4096,)            float32_ref\n",
      "[TL]   param  13: model/output/W:0     (1024, 8004)       float32_ref\n",
      "[TL]   param  14: model/output/b:0     (8004,)            float32_ref\n",
      "[TL]   num of params: 66756420\n",
      "[TL] WARNING: From <ipython-input-15-a61d1b7a1d3e>:138: initialize_global_variables (from tensorlayer.layers.utils) is deprecated and will be removed after 2018-09-30.\n",
      "Instructions for updating: This API is deprecated in favor of `tf.global_variables_initializer`\n",
      "\n",
      "[TL] [!] Load n.npz failed!\n",
      "Epoch[0/50] step:[0/2110] loss:9.326397 took:1.46026s\n",
      "Epoch[0/50] step:[200/2110] loss:6.075531 took:0.41821s\n",
      "Epoch[0/50] step:[400/2110] loss:5.988945 took:0.46098s\n",
      "Epoch[0/50] step:[600/2110] loss:5.970472 took:0.37068s\n",
      "Epoch[0/50] step:[800/2110] loss:5.766476 took:0.40379s\n",
      "Query > happy birthday have a nice day\n",
      " > no you\n",
      " > i i you\n",
      " > i i\n",
      " > i you\n",
      " > no i\n",
      "Query > how was it going\n",
      " > you you\n",
      " > i you\n",
      " > no you\n",
      " > i i\n",
      " > i you you\n",
      "Epoch[0/50] step:[1000/2110] loss:5.505304 took:0.41839s\n",
      "Epoch[0/50] step:[1200/2110] loss:5.810014 took:0.45869s\n",
      "Epoch[0/50] step:[1400/2110] loss:5.776262 took:0.45274s\n",
      "Epoch[0/50] step:[1600/2110] loss:5.835141 took:0.42430s\n",
      "Epoch[0/50] step:[1800/2110] loss:5.952801 took:0.45348s\n",
      "Query > happy birthday have a nice day\n",
      " > i you\n",
      " > i you you\n",
      " > i i\n",
      " > i you you you\n",
      " > i you\n",
      "Query > how was it going\n",
      " > i you\n",
      " > no i you\n",
      " > you you\n",
      " > you you\n",
      " > you i\n",
      "Epoch[0/50] step:[2000/2110] loss:5.792002 took:0.40465s\n",
      "Epoch[0/50] averaged loss:6.069655 took:944.22911s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[1/50] step:[0/2110] loss:6.051829 took:0.54775s\n",
      "Epoch[1/50] step:[200/2110] loss:5.946949 took:0.45389s\n",
      "Epoch[1/50] step:[400/2110] loss:6.099279 took:0.46364s\n",
      "Epoch[1/50] step:[600/2110] loss:5.645317 took:0.46283s\n",
      "Epoch[1/50] step:[800/2110] loss:5.907260 took:0.50171s\n",
      "Query > happy birthday have a nice day\n",
      " > you dont\n",
      " > i dont you know\n",
      " > i dont know\n",
      " > i dont you know\n",
      " > i know you\n",
      "Query > how was it going\n",
      " > i dont know you\n",
      " > i dont know\n",
      " > i dont know you\n",
      " > i know\n",
      " > i know\n",
      "Epoch[1/50] step:[1000/2110] loss:5.667645 took:0.44074s\n",
      "Epoch[1/50] step:[1200/2110] loss:5.708266 took:0.41952s\n",
      "Epoch[1/50] step:[1400/2110] loss:5.227110 took:0.44874s\n",
      "Epoch[1/50] step:[1600/2110] loss:5.348544 took:0.43882s\n",
      "Epoch[1/50] step:[1800/2110] loss:5.484311 took:0.48010s\n",
      "Query > happy birthday have a nice day\n",
      " > you dont think to do\n",
      " > i know\n",
      " > what i know you\n",
      " > i know\n",
      " > i dont think to do\n",
      "Query > how was it going\n",
      " > i dont know\n",
      " > i dont know\n",
      " > i know\n",
      " > i dont know to\n",
      " > i know\n",
      "Epoch[1/50] step:[2000/2110] loss:5.742533 took:0.43266s\n",
      "Epoch[1/50] averaged loss:5.698062 took:946.36171s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[2/50] step:[0/2110] loss:5.663057 took:0.55994s\n",
      "Epoch[2/50] step:[200/2110] loss:5.723967 took:0.40129s\n",
      "Epoch[2/50] step:[400/2110] loss:5.197671 took:0.42241s\n",
      "Epoch[2/50] step:[600/2110] loss:5.241144 took:0.40763s\n",
      "Epoch[2/50] step:[800/2110] loss:5.255385 took:0.45277s\n",
      "Query > happy birthday have a nice day\n",
      " > no i know\n",
      " > you dont know\n",
      " > i dont know\n",
      " > you know\n",
      " > no unk i dont know\n",
      "Query > how was it going\n",
      " > i dont know it\n",
      " > i dont know\n",
      " > you know\n",
      " > you dont know\n",
      " > i dont know it\n",
      "Epoch[2/50] step:[1000/2110] loss:5.065025 took:0.40507s\n",
      "Epoch[2/50] step:[1200/2110] loss:5.271741 took:0.48263s\n",
      "Epoch[2/50] step:[1400/2110] loss:5.085358 took:0.43314s\n",
      "Epoch[2/50] step:[1600/2110] loss:5.298048 took:0.45225s\n",
      "Epoch[2/50] step:[1800/2110] loss:4.854000 took:0.43986s\n",
      "Query > happy birthday have a nice day\n",
      " > i dont know i know i dont know\n",
      " > no i dont know\n",
      " > no i dont know i dont think\n",
      " > no i dont know i dont know\n",
      " > no i dont think i dont know i was a unk\n",
      "Query > how was it going\n",
      " > i dont know\n",
      " > i dont think i know\n",
      " > i dont know\n",
      " > you know i dont know\n",
      " > i dont know i dont know\n",
      "Epoch[2/50] step:[2000/2110] loss:5.109505 took:0.42913s\n",
      "Epoch[2/50] averaged loss:5.372604 took:946.50438s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[3/50] step:[0/2110] loss:5.107849 took:0.60005s\n",
      "Epoch[3/50] step:[200/2110] loss:5.327825 took:0.43411s\n",
      "Epoch[3/50] step:[400/2110] loss:5.268231 took:0.44445s\n",
      "Epoch[3/50] step:[600/2110] loss:5.437715 took:0.49846s\n",
      "Epoch[3/50] step:[800/2110] loss:5.300061 took:0.42722s\n",
      "Query > happy birthday have a nice day\n",
      " > i dont know\n",
      " > you know\n",
      " > no i dont want to be a little unk\n",
      " > i dont know that\n",
      " > i know\n",
      "Query > how was it going\n",
      " > i know i was a unk\n",
      " > i dont know what i dont know\n",
      " > i know i dont know i know i dont want to go\n",
      " > you dont know what you mean\n",
      " > unk unk\n",
      "Epoch[3/50] step:[1000/2110] loss:4.903152 took:0.48171s\n",
      "Epoch[3/50] step:[1200/2110] loss:5.047695 took:0.37101s\n",
      "Epoch[3/50] step:[1400/2110] loss:5.199926 took:0.44012s\n",
      "Epoch[3/50] step:[1600/2110] loss:5.029301 took:0.44839s\n",
      "Epoch[3/50] step:[1800/2110] loss:5.132384 took:0.47393s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query > happy birthday have a nice day\n",
      " > you dont know that\n",
      " > i dont know\n",
      " > i know i was unk\n",
      " > you know i dont know i was a unk\n",
      " > i dont know\n",
      "Query > how was it going\n",
      " > i know\n",
      " > i dont want to go\n",
      " > i dont know\n",
      " > i dont know\n",
      " > i dont know\n",
      "Epoch[3/50] step:[2000/2110] loss:5.047546 took:0.44560s\n",
      "Epoch[3/50] averaged loss:5.171223 took:946.28060s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[4/50] step:[0/2110] loss:4.750675 took:0.59983s\n",
      "Epoch[4/50] step:[200/2110] loss:4.885523 took:0.47944s\n",
      "Epoch[4/50] step:[400/2110] loss:5.154873 took:0.45554s\n",
      "Epoch[4/50] step:[600/2110] loss:5.111124 took:0.47352s\n",
      "Epoch[4/50] step:[800/2110] loss:4.935506 took:0.40880s\n",
      "Query > happy birthday have a nice day\n",
      " > i know i know\n",
      " > no i dont know\n",
      " > yeah you know\n",
      " > i dont know\n",
      " > yeah i dont know\n",
      "Query > how was it going\n",
      " > i dont know\n",
      " > i dont know\n",
      " > i dont know i dont know\n",
      " > i know\n",
      " > i dont know\n",
      "Epoch[4/50] step:[1000/2110] loss:5.263610 took:0.41745s\n",
      "Epoch[4/50] step:[1200/2110] loss:5.094879 took:0.48180s\n",
      "Epoch[4/50] step:[1400/2110] loss:5.186944 took:0.45504s\n",
      "Epoch[4/50] step:[1600/2110] loss:4.848894 took:0.45456s\n",
      "Epoch[4/50] step:[1800/2110] loss:4.915626 took:0.48908s\n",
      "Query > happy birthday have a nice day\n",
      " > you know\n",
      " > no no i dont know what i want to do\n",
      " > i dont think\n",
      " > i dont think\n",
      " > i dont think\n",
      "Query > how was it going\n",
      " > you dont know\n",
      " > i know i dont think i dont think\n",
      " > i dont know what you mean\n",
      " > its a good unk\n",
      " > i dont know\n",
      "Epoch[4/50] step:[2000/2110] loss:5.175938 took:0.45615s\n",
      "Epoch[4/50] averaged loss:5.047835 took:946.81114s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[5/50] step:[0/2110] loss:5.005917 took:0.58112s\n",
      "Epoch[5/50] step:[200/2110] loss:4.813627 took:0.39600s\n",
      "Epoch[5/50] step:[400/2110] loss:4.902840 took:0.41345s\n",
      "Epoch[5/50] step:[600/2110] loss:5.025625 took:0.49007s\n",
      "Epoch[5/50] step:[800/2110] loss:4.683101 took:0.40323s\n",
      "Query > happy birthday have a nice day\n",
      " > you know\n",
      " > i know i know i dont know i dont know\n",
      " > no no no i know\n",
      " > no i know\n",
      " > no no i know\n",
      "Query > how was it going\n",
      " > i dont know i know\n",
      " > unk unk\n",
      " > you know i dont know\n",
      " > you dont know\n",
      " > i dont know\n",
      "Epoch[5/50] step:[1000/2110] loss:5.248272 took:0.46194s\n",
      "Epoch[5/50] step:[1200/2110] loss:4.725928 took:0.42373s\n",
      "Epoch[5/50] step:[1400/2110] loss:5.214324 took:0.46509s\n",
      "Epoch[5/50] step:[1600/2110] loss:5.311023 took:0.42633s\n",
      "Epoch[5/50] step:[1800/2110] loss:4.735269 took:0.47410s\n",
      "Query > happy birthday have a nice day\n",
      " > i know\n",
      " > you dont know\n",
      " > no i dont know\n",
      " > you dont have to go\n",
      " > i know i dont know what i was unk\n",
      "Query > how was it going\n",
      " > i dont know i dont know\n",
      " > i dont think so\n",
      " > i dont know i dont know\n",
      " > oh i dont know\n",
      " > oh no i dont know i know i dont know\n",
      "Epoch[5/50] step:[2000/2110] loss:4.846779 took:0.45771s\n",
      "Epoch[5/50] averaged loss:4.958325 took:944.66090s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[6/50] step:[0/2110] loss:5.251311 took:0.56111s\n",
      "Epoch[6/50] step:[200/2110] loss:4.286991 took:0.37454s\n",
      "Epoch[6/50] step:[400/2110] loss:4.974790 took:0.48847s\n",
      "Epoch[6/50] step:[600/2110] loss:4.705732 took:0.40970s\n",
      "Epoch[6/50] step:[800/2110] loss:4.754533 took:0.45273s\n",
      "Query > happy birthday have a nice day\n",
      " > you dont have a lot of unk\n",
      " > you know\n",
      " > no no i dont think i dont want to see you\n",
      " > i know\n",
      " > i dont know\n",
      "Query > how was it going\n",
      " > i dont know\n",
      " > i dont know\n",
      " > i dont think so i dont know\n",
      " > you know i dont know what you want\n",
      " > i dont know what i do\n",
      "Epoch[6/50] step:[1000/2110] loss:4.868209 took:0.43572s\n",
      "Epoch[6/50] step:[1200/2110] loss:4.858804 took:0.43394s\n",
      "Epoch[6/50] step:[1400/2110] loss:4.894337 took:0.47318s\n",
      "Epoch[6/50] step:[1600/2110] loss:4.740751 took:0.46420s\n",
      "Epoch[6/50] step:[1800/2110] loss:5.103901 took:0.49790s\n",
      "Query > happy birthday have a nice day\n",
      " > you know\n",
      " > i know i dont know\n",
      " > i dont know\n",
      " > i dont know what you want\n",
      " > i dont know\n",
      "Query > how was it going\n",
      " > i dont know\n",
      " > i know\n",
      " > i dont know\n",
      " > i dont know\n",
      " > you dont know what you mean i dont know\n",
      "Epoch[6/50] step:[2000/2110] loss:4.783827 took:0.40478s\n",
      "Epoch[6/50] averaged loss:4.881101 took:943.48974s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[7/50] step:[0/2110] loss:4.666324 took:0.53344s\n",
      "Epoch[7/50] step:[200/2110] loss:4.737160 took:0.45281s\n",
      "Epoch[7/50] step:[400/2110] loss:4.771996 took:0.36591s\n",
      "Epoch[7/50] step:[600/2110] loss:4.438112 took:0.40358s\n",
      "Epoch[7/50] step:[800/2110] loss:4.829183 took:0.42140s\n",
      "Query > happy birthday have a nice day\n",
      " > you know what you want\n",
      " > no i dont know\n",
      " > i know\n",
      " > you dont know what i mean\n",
      " > no no no no no no no no\n",
      "Query > how was it going\n",
      " > i dont know\n",
      " > i dont know\n",
      " > you dont know what you mean about it\n",
      " > i dont know\n",
      " > you dont know\n",
      "Epoch[7/50] step:[1000/2110] loss:4.868910 took:0.46097s\n",
      "Epoch[7/50] step:[1200/2110] loss:5.209962 took:0.45370s\n",
      "Epoch[7/50] step:[1400/2110] loss:4.778344 took:0.48500s\n",
      "Epoch[7/50] step:[1600/2110] loss:5.110377 took:0.44182s\n",
      "Epoch[7/50] step:[1800/2110] loss:5.151065 took:0.47348s\n",
      "Query > happy birthday have a nice day\n",
      " > no no no no i just dont want to know\n",
      " > i dont know\n",
      " > i dont know\n",
      " > i dont know\n",
      " > i dont know\n",
      "Query > how was it going\n",
      " > i dont know\n",
      " > i dont know what i mean i dont know\n",
      " > i dont know\n",
      " > you know i know\n",
      " > i dont know\n",
      "Epoch[7/50] step:[2000/2110] loss:4.703472 took:0.39659s\n",
      "Epoch[7/50] averaged loss:4.818376 took:946.12204s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[8/50] step:[0/2110] loss:4.904327 took:0.57605s\n",
      "Epoch[8/50] step:[200/2110] loss:4.593842 took:0.47532s\n",
      "Epoch[8/50] step:[400/2110] loss:5.047787 took:0.45293s\n",
      "Epoch[8/50] step:[600/2110] loss:4.735042 took:0.46409s\n",
      "Epoch[8/50] step:[800/2110] loss:4.791676 took:0.43474s\n",
      "Query > happy birthday have a nice day\n",
      " > you know what you mean\n",
      " > i dont think so\n",
      " > i dont think i dont want to talk to you\n",
      " > i know\n",
      " > i dont know\n",
      "Query > how was it going\n",
      " > you dont know what you mean\n",
      " > i know i know\n",
      " > i know\n",
      " > you dont know\n",
      " > i know i dont know\n",
      "Epoch[8/50] step:[1000/2110] loss:4.548040 took:0.43787s\n",
      "Epoch[8/50] step:[1200/2110] loss:4.620372 took:0.40979s\n",
      "Epoch[8/50] step:[1400/2110] loss:5.012816 took:0.45888s\n",
      "Epoch[8/50] step:[1600/2110] loss:5.090574 took:0.44736s\n",
      "Epoch[8/50] step:[1800/2110] loss:4.830169 took:0.45253s\n",
      "Query > happy birthday have a nice day\n",
      " > no no no\n",
      " > i dont know\n",
      " > you know what i mean\n",
      " > you know what you mean\n",
      " > i know\n",
      "Query > how was it going\n",
      " > i dont know\n",
      " > i dont know what i want\n",
      " > it was a unk\n",
      " > i know\n",
      " > it is\n",
      "Epoch[8/50] step:[2000/2110] loss:4.425079 took:0.47476s\n",
      "Epoch[8/50] averaged loss:4.760433 took:945.39585s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[9/50] step:[0/2110] loss:4.847485 took:0.51690s\n",
      "Epoch[9/50] step:[200/2110] loss:4.607712 took:0.45181s\n",
      "Epoch[9/50] step:[400/2110] loss:4.600953 took:0.44679s\n",
      "Epoch[9/50] step:[600/2110] loss:4.683976 took:0.48680s\n",
      "Epoch[9/50] step:[800/2110] loss:4.418357 took:0.45044s\n",
      "Query > happy birthday have a nice day\n",
      " > i know\n",
      " > i know\n",
      " > no i dont know what i want to do\n",
      " > i dont know\n",
      " > i dont know what i mean i dont know\n",
      "Query > how was it going\n",
      " > i dont know\n",
      " > i dont know i know i dont know what i mean\n",
      " > i dont know\n",
      " > i dont know\n",
      " > i dont know\n",
      "Epoch[9/50] step:[1000/2110] loss:4.767841 took:0.43955s\n",
      "Epoch[9/50] step:[1200/2110] loss:4.736037 took:0.48227s\n",
      "Epoch[9/50] step:[1400/2110] loss:4.469364 took:0.46672s\n",
      "Epoch[9/50] step:[1600/2110] loss:4.561964 took:0.47633s\n",
      "Epoch[9/50] step:[1800/2110] loss:4.625519 took:0.45100s\n",
      "Query > happy birthday have a nice day\n",
      " > i dont think so i dont want you to be a unk\n",
      " > i know\n",
      " > you know\n",
      " > i know i dont know what you mean\n",
      " > you have a lot of unk\n",
      "Query > how was it going\n",
      " > i dont know\n",
      " > you know\n",
      " > i dont know\n",
      " > i dont know i dont know\n",
      " > i dont know\n",
      "Epoch[9/50] step:[2000/2110] loss:4.415327 took:0.33732s\n",
      "Epoch[9/50] averaged loss:4.710640 took:945.20030s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[10/50] step:[0/2110] loss:4.694071 took:0.59834s\n",
      "Epoch[10/50] step:[200/2110] loss:4.714733 took:0.43321s\n",
      "Epoch[10/50] step:[400/2110] loss:4.915998 took:0.46502s\n",
      "Epoch[10/50] step:[600/2110] loss:4.907130 took:0.44348s\n",
      "Epoch[10/50] step:[800/2110] loss:4.729483 took:0.45621s\n",
      "Query > happy birthday have a nice day\n",
      " > i dont know what i want to be a little unk\n",
      " > i know\n",
      " > i dont know what i want to do\n",
      " > you know what i mean i was a unk unk\n",
      " > you know what i mean\n",
      "Query > how was it going\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > you know what i was\n",
      " > it was a good time\n",
      " > i dont know\n",
      " > you know what i mean\n",
      " > it was a unk unk and a unk\n",
      "Epoch[10/50] step:[1000/2110] loss:4.881660 took:0.47982s\n",
      "Epoch[10/50] step:[1200/2110] loss:4.535581 took:0.46348s\n",
      "Epoch[10/50] step:[1400/2110] loss:4.938489 took:0.43730s\n",
      "Epoch[10/50] step:[1600/2110] loss:4.856382 took:0.45817s\n",
      "Epoch[10/50] step:[1800/2110] loss:4.792933 took:0.46189s\n",
      "Query > happy birthday have a nice day\n",
      " > no no no no\n",
      " > no i just want to see you\n",
      " > i dont know\n",
      " > i dont know\n",
      " > i dont know what youre talking about\n",
      "Query > how was it going\n",
      " > you know\n",
      " > i dont know i dont know\n",
      " > i dont know\n",
      " > you know i dont know\n",
      " > i know\n",
      "Epoch[10/50] step:[2000/2110] loss:4.532131 took:0.41012s\n",
      "Epoch[10/50] averaged loss:4.660116 took:946.55879s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[11/50] step:[0/2110] loss:4.822689 took:0.60816s\n",
      "Epoch[11/50] step:[200/2110] loss:4.423930 took:0.41317s\n",
      "Epoch[11/50] step:[400/2110] loss:4.539880 took:0.41891s\n",
      "Epoch[11/50] step:[600/2110] loss:4.279769 took:0.45324s\n",
      "Epoch[11/50] step:[800/2110] loss:4.879057 took:0.46038s\n",
      "Query > happy birthday have a nice day\n",
      " > no i dont know what i want to be\n",
      " > you know what you mean\n",
      " > no no\n",
      " > i dont know what youre talking about\n",
      " > no i think so\n",
      "Query > how was it going\n",
      " > i dont know\n",
      " > i dont know\n",
      " > i dont know\n",
      " > i dont know\n",
      " > i dont know\n",
      "Epoch[11/50] step:[1000/2110] loss:4.695729 took:0.49330s\n",
      "Epoch[11/50] step:[1200/2110] loss:4.708426 took:0.39306s\n",
      "Epoch[11/50] step:[1400/2110] loss:4.766227 took:0.44554s\n",
      "Epoch[11/50] step:[1600/2110] loss:4.487628 took:0.44191s\n",
      "Epoch[11/50] step:[1800/2110] loss:4.917553 took:0.44878s\n",
      "Query > happy birthday have a nice day\n",
      " > you know what i mean\n",
      " > no i dont know\n",
      " > i know\n",
      " > you dont have to be here\n",
      " > you know that\n",
      "Query > how was it going\n",
      " > i dont know i dont think so\n",
      " > i dont know\n",
      " > i dont know i know\n",
      " > i dont know\n",
      " > you dont know what you mean\n",
      "Epoch[11/50] step:[2000/2110] loss:4.748397 took:0.40256s\n",
      "Epoch[11/50] averaged loss:4.613729 took:945.50841s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[12/50] step:[0/2110] loss:4.525655 took:0.59599s\n",
      "Epoch[12/50] step:[200/2110] loss:4.515454 took:0.43637s\n",
      "Epoch[12/50] step:[400/2110] loss:4.433680 took:0.47067s\n",
      "Epoch[12/50] step:[600/2110] loss:4.310381 took:0.48661s\n",
      "Epoch[12/50] step:[800/2110] loss:4.352765 took:0.45803s\n",
      "Query > happy birthday have a nice day\n",
      " > i dont know what i mean\n",
      " > you know what i mean\n",
      " > you dont know what youre talking about\n",
      " > its a unk unk\n",
      " > i know\n",
      "Query > how was it going\n",
      " > it was a unk unk\n",
      " > i dont think so\n",
      " > it was a unk unk\n",
      " > i dont know\n",
      " > it was the only thing\n",
      "Epoch[12/50] step:[1000/2110] loss:4.535077 took:0.39823s\n",
      "Epoch[12/50] step:[1200/2110] loss:4.779942 took:0.48050s\n",
      "Epoch[12/50] step:[1400/2110] loss:4.615564 took:0.42889s\n",
      "Epoch[12/50] step:[1600/2110] loss:4.315217 took:0.46257s\n",
      "Epoch[12/50] step:[1800/2110] loss:4.477183 took:0.47102s\n",
      "Query > happy birthday have a nice day\n",
      " > i dont know\n",
      " > i know\n",
      " > i know\n",
      " > no no no no no\n",
      " > i dont think so\n",
      "Query > how was it going\n",
      " > i dont know\n",
      " > i dont know\n",
      " > it was a unk\n",
      " > i dont know\n",
      " > i dont know\n",
      "Epoch[12/50] step:[2000/2110] loss:4.533558 took:0.41734s\n",
      "Epoch[12/50] averaged loss:4.567791 took:947.89371s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[13/50] step:[0/2110] loss:4.789667 took:0.58134s\n",
      "Epoch[13/50] step:[200/2110] loss:3.988822 took:0.37486s\n",
      "Epoch[13/50] step:[400/2110] loss:4.660324 took:0.45639s\n",
      "Epoch[13/50] step:[600/2110] loss:4.602961 took:0.46581s\n",
      "Epoch[13/50] step:[800/2110] loss:4.513416 took:0.46686s\n",
      "Query > happy birthday have a nice day\n",
      " > you know what i do\n",
      " > you know that\n",
      " > no i dont know\n",
      " > i dont think so\n",
      " > i dont know what youre talking about\n",
      "Query > how was it going\n",
      " > it was a unk\n",
      " > it was a unk\n",
      " > i dont know i know\n",
      " > i dont know\n",
      " > i dont know\n",
      "Epoch[13/50] step:[1000/2110] loss:4.672003 took:0.42852s\n",
      "Epoch[13/50] step:[1200/2110] loss:4.518003 took:0.41958s\n",
      "Epoch[13/50] step:[1400/2110] loss:4.524786 took:0.46347s\n",
      "Epoch[13/50] step:[1600/2110] loss:4.178337 took:0.40731s\n",
      "Epoch[13/50] step:[1800/2110] loss:4.362234 took:0.43347s\n",
      "Query > happy birthday have a nice day\n",
      " > i know\n",
      " > i know\n",
      " > no i dont think so\n",
      " > no no no no no\n",
      " > i dont think so\n",
      "Query > how was it going\n",
      " > i dont know i dont know i just dont know\n",
      " > i dont know i just dont know\n",
      " > i dont know i dont think i could be able to be a unk\n",
      " > it was a good time to see the unk of unk\n",
      " > it was a unk\n",
      "Epoch[13/50] step:[2000/2110] loss:4.268851 took:0.46448s\n",
      "Epoch[13/50] averaged loss:4.523157 took:948.67174s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[14/50] step:[0/2110] loss:4.348451 took:0.50748s\n",
      "Epoch[14/50] step:[200/2110] loss:4.421496 took:0.46813s\n",
      "Epoch[14/50] step:[400/2110] loss:4.523458 took:0.45244s\n",
      "Epoch[14/50] step:[600/2110] loss:4.915356 took:0.37627s\n",
      "Epoch[14/50] step:[800/2110] loss:4.391902 took:0.39203s\n",
      "Query > happy birthday have a nice day\n",
      " > i dont think so\n",
      " > i know\n",
      " > its a good time\n",
      " > no no\n",
      " > i dont know\n",
      "Query > how was it going\n",
      " > you know\n",
      " > it was a good time\n",
      " > it was a unk\n",
      " > it was a unk\n",
      " > i dont know\n",
      "Epoch[14/50] step:[1000/2110] loss:4.288081 took:0.48409s\n",
      "Epoch[14/50] step:[1200/2110] loss:4.209010 took:0.45635s\n",
      "Epoch[14/50] step:[1400/2110] loss:4.531441 took:0.50405s\n",
      "Epoch[14/50] step:[1600/2110] loss:4.745330 took:0.44488s\n",
      "Epoch[14/50] step:[1800/2110] loss:4.849721 took:0.50624s\n",
      "Query > happy birthday have a nice day\n",
      " > i know\n",
      " > you know what you want\n",
      " > its a unk\n",
      " > its a unk\n",
      " > i know\n",
      "Query > how was it going\n",
      " > i was unk\n",
      " > you dont know\n",
      " > i was going to see you\n",
      " > you know what you mean\n",
      " > i dont know\n",
      "Epoch[14/50] step:[2000/2110] loss:4.699096 took:0.37261s\n",
      "Epoch[14/50] averaged loss:4.479542 took:950.96761s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[15/50] step:[0/2110] loss:4.697073 took:0.53194s\n",
      "Epoch[15/50] step:[200/2110] loss:4.743111 took:0.42845s\n",
      "Epoch[15/50] step:[400/2110] loss:4.556319 took:0.46271s\n",
      "Epoch[15/50] step:[600/2110] loss:4.551310 took:0.47566s\n",
      "Epoch[15/50] step:[800/2110] loss:4.454859 took:0.46455s\n",
      "Query > happy birthday have a nice day\n",
      " > i know\n",
      " > its not that\n",
      " > i know i know i know\n",
      " > i know\n",
      " > its a unk\n",
      "Query > how was it going\n",
      " > you know i dont know what i want to do with it\n",
      " > i dont know\n",
      " > you dont know\n",
      " > i dont know\n",
      " > i dont know i dont know\n",
      "Epoch[15/50] step:[1000/2110] loss:4.447855 took:0.43261s\n",
      "Epoch[15/50] step:[1200/2110] loss:4.406447 took:0.41912s\n",
      "Epoch[15/50] step:[1400/2110] loss:4.390499 took:0.44932s\n",
      "Epoch[15/50] step:[1600/2110] loss:4.443919 took:0.47965s\n",
      "Epoch[15/50] step:[1800/2110] loss:4.575605 took:0.49054s\n",
      "Query > happy birthday have a nice day\n",
      " > i know\n",
      " > i dont think so\n",
      " > you mean it is\n",
      " > no i think i can\n",
      " > i dont know\n",
      "Query > how was it going\n",
      " > you know what i mean\n",
      " > i dont know\n",
      " > i was unk\n",
      " > you know i dont know\n",
      " > i dont know\n",
      "Epoch[15/50] step:[2000/2110] loss:4.521941 took:0.47263s\n",
      "Epoch[15/50] averaged loss:4.435171 took:951.79316s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[16/50] step:[0/2110] loss:4.254152 took:0.52968s\n",
      "Epoch[16/50] step:[200/2110] loss:4.865182 took:0.49846s\n",
      "Epoch[16/50] step:[400/2110] loss:4.481932 took:0.45292s\n",
      "Epoch[16/50] step:[600/2110] loss:4.672838 took:0.41902s\n",
      "Epoch[16/50] step:[800/2110] loss:4.349423 took:0.47459s\n",
      "Query > happy birthday have a nice day\n",
      " > you know that\n",
      " > i dont know what i mean\n",
      " > its not that\n",
      " > i know\n",
      " > i dont know\n",
      "Query > how was it going\n",
      " > it was a long time\n",
      " > i dont know\n",
      " > i was unk\n",
      " > i dont know\n",
      " > it was a long time ago\n",
      "Epoch[16/50] step:[1000/2110] loss:4.493305 took:0.41349s\n",
      "Epoch[16/50] step:[1200/2110] loss:4.553301 took:0.43769s\n",
      "Epoch[16/50] step:[1400/2110] loss:4.480216 took:0.47361s\n",
      "Epoch[16/50] step:[1600/2110] loss:4.377682 took:0.49497s\n",
      "Epoch[16/50] step:[1800/2110] loss:4.272167 took:0.47344s\n",
      "Query > happy birthday have a nice day\n",
      " > i dont know\n",
      " > its not the same\n",
      " > its not a long time\n",
      " > i dont think so\n",
      " > its not a long time\n",
      "Query > how was it going\n",
      " > i dont know\n",
      " > oh well i dont know what i mean\n",
      " > i dont know i dont know i dont know\n",
      " > i dont know i dont know\n",
      " > i dont know\n",
      "Epoch[16/50] step:[2000/2110] loss:3.973788 took:0.47111s\n",
      "Epoch[16/50] averaged loss:4.390484 took:949.88376s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[17/50] step:[0/2110] loss:4.563370 took:0.56413s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[17/50] step:[200/2110] loss:4.529686 took:0.45110s\n",
      "Epoch[17/50] step:[400/2110] loss:4.546711 took:0.38889s\n",
      "Epoch[17/50] step:[600/2110] loss:4.140928 took:0.41571s\n",
      "Epoch[17/50] step:[800/2110] loss:4.049947 took:0.43345s\n",
      "Query > happy birthday have a nice day\n",
      " > its a unk\n",
      " > i know i dont know what youre talking about\n",
      " > i know i know\n",
      " > i know\n",
      " > i know\n",
      "Query > how was it going\n",
      " > i dont know\n",
      " > i dont know\n",
      " > i dont know\n",
      " > it was a unk\n",
      " > i dont know i just dont know\n",
      "Epoch[17/50] step:[1000/2110] loss:4.311115 took:0.44707s\n",
      "Epoch[17/50] step:[1200/2110] loss:4.441726 took:0.43689s\n",
      "Epoch[17/50] step:[1400/2110] loss:4.357040 took:0.44105s\n",
      "Epoch[17/50] step:[1600/2110] loss:4.606152 took:0.41505s\n",
      "Epoch[17/50] step:[1800/2110] loss:4.484820 took:0.43165s\n",
      "Query > happy birthday have a nice day\n",
      " > i dont know\n",
      " > i dont know\n",
      " > thank you\n",
      " > i dont know\n",
      " > i dont know\n",
      "Query > how was it going\n",
      " > it was a long time ago\n",
      " > oh i dont know\n",
      " > i dont know\n",
      " > it was a long time ago\n",
      " > oh fine\n",
      "Epoch[17/50] step:[2000/2110] loss:4.550154 took:0.48129s\n",
      "Epoch[17/50] averaged loss:4.347042 took:951.34130s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[18/50] step:[0/2110] loss:4.600670 took:0.44928s\n",
      "Epoch[18/50] step:[200/2110] loss:4.148629 took:0.44568s\n",
      "Epoch[18/50] step:[400/2110] loss:4.433005 took:0.43420s\n",
      "Epoch[18/50] step:[600/2110] loss:4.492455 took:0.48067s\n",
      "Epoch[18/50] step:[800/2110] loss:3.985578 took:0.45302s\n",
      "Query > happy birthday have a nice day\n",
      " > i know i know\n",
      " > its a unk\n",
      " > its a unk\n",
      " > no it is\n",
      " > its a unk\n",
      "Query > how was it going\n",
      " > i dont know\n",
      " > i dont know\n",
      " > oh well i dont think so\n",
      " > i dont know i just dont know\n",
      " > i dont know\n",
      "Epoch[18/50] step:[1000/2110] loss:4.445104 took:0.49888s\n",
      "Epoch[18/50] step:[1200/2110] loss:4.202390 took:0.46693s\n",
      "Epoch[18/50] step:[1400/2110] loss:4.114493 took:0.43378s\n",
      "Epoch[18/50] step:[1600/2110] loss:4.634367 took:0.41457s\n",
      "Epoch[18/50] step:[1800/2110] loss:4.257413 took:0.44128s\n",
      "Query > happy birthday have a nice day\n",
      " > thank you\n",
      " > i know\n",
      " > i dont know what to do with it\n",
      " > its a unk\n",
      " > its a unk\n",
      "Query > how was it going\n",
      " > i dont know i dont know\n",
      " > it wasnt a unk\n",
      " > i dont know\n",
      " > it was a long time ago\n",
      " > it wasnt the unk\n",
      "Epoch[18/50] step:[2000/2110] loss:4.385620 took:0.46007s\n",
      "Epoch[18/50] averaged loss:4.301407 took:949.26397s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[19/50] step:[0/2110] loss:4.153521 took:0.53928s\n",
      "Epoch[19/50] step:[200/2110] loss:4.404124 took:0.42982s\n",
      "Epoch[19/50] step:[400/2110] loss:4.359375 took:0.43296s\n",
      "Epoch[19/50] step:[600/2110] loss:4.319453 took:0.44496s\n",
      "Epoch[19/50] step:[800/2110] loss:4.415174 took:0.46910s\n",
      "Query > happy birthday have a nice day\n",
      " > no it was a unk unk\n",
      " > its a unk\n",
      " > i dont know\n",
      " > i know\n",
      " > its a unk\n",
      "Query > how was it going\n",
      " > it was a long time ago i was unk\n",
      " > i dont know\n",
      " > you know it\n",
      " > i was unk\n",
      " > it wasnt a good time\n",
      "Epoch[19/50] step:[1000/2110] loss:4.224121 took:0.39664s\n",
      "Epoch[19/50] step:[1200/2110] loss:4.099304 took:0.44344s\n",
      "Epoch[19/50] step:[1400/2110] loss:4.298156 took:0.50927s\n",
      "Epoch[19/50] step:[1600/2110] loss:4.299778 took:0.42328s\n",
      "Epoch[19/50] step:[1800/2110] loss:4.722218 took:0.46848s\n",
      "Query > happy birthday have a nice day\n",
      " > its a unk\n",
      " > i dont think its a unk\n",
      " > thank you\n",
      " > thank you\n",
      " > thank you sir\n",
      "Query > how was it going\n",
      " > you know i dont know\n",
      " > it was a long time ago\n",
      " > you know\n",
      " > i dont know\n",
      " > i dont know\n",
      "Epoch[19/50] step:[2000/2110] loss:4.373997 took:0.47582s\n",
      "Epoch[19/50] averaged loss:4.258035 took:951.36475s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[20/50] step:[0/2110] loss:3.859467 took:0.56299s\n",
      "Epoch[20/50] step:[200/2110] loss:4.593874 took:0.48965s\n",
      "Epoch[20/50] step:[400/2110] loss:4.250521 took:0.43839s\n",
      "Epoch[20/50] step:[600/2110] loss:4.216348 took:0.47306s\n",
      "Epoch[20/50] step:[800/2110] loss:3.901485 took:0.43353s\n",
      "Query > happy birthday have a nice day\n",
      " > i dont know\n",
      " > i know you were unk and unk\n",
      " > i know you are\n",
      " > thank you\n",
      " > i dont think so\n",
      "Query > how was it going\n",
      " > i was unk to see you\n",
      " > i dont know i dont know\n",
      " > i dont know\n",
      " > it was the unk of unk unk\n",
      " > i dont know\n",
      "Epoch[20/50] step:[1000/2110] loss:4.450779 took:0.36658s\n",
      "Epoch[20/50] step:[1200/2110] loss:3.993658 took:0.43279s\n",
      "Epoch[20/50] step:[1400/2110] loss:4.356887 took:0.48113s\n",
      "Epoch[20/50] step:[1600/2110] loss:4.021652 took:0.43726s\n",
      "Epoch[20/50] step:[1800/2110] loss:4.059429 took:0.40779s\n",
      "Query > happy birthday have a nice day\n",
      " > i know\n",
      " > thank you\n",
      " > thank you sir i am\n",
      " > i know you are\n",
      " > thank you sir\n",
      "Query > how was it going\n",
      " > i dont know\n",
      " > it was good\n",
      " > i was unk\n",
      " > it was a good time\n",
      " > i dont know\n",
      "Epoch[20/50] step:[2000/2110] loss:4.185133 took:0.45636s\n",
      "Epoch[20/50] averaged loss:4.214198 took:951.45853s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[21/50] step:[0/2110] loss:4.059863 took:0.55196s\n",
      "Epoch[21/50] step:[200/2110] loss:4.302220 took:0.47925s\n",
      "Epoch[21/50] step:[400/2110] loss:4.149060 took:0.49131s\n",
      "Epoch[21/50] step:[600/2110] loss:4.006958 took:0.46203s\n",
      "Epoch[21/50] step:[800/2110] loss:4.309509 took:0.48521s\n",
      "Query > happy birthday have a nice day\n",
      " > its not a good\n",
      " > its not a long time\n",
      " > thank god sir\n",
      " > its a good time\n",
      " > thank you\n",
      "Query > how was it going\n",
      " > oh i dont know\n",
      " > i dont know\n",
      " > it was the only one\n",
      " > i dont know\n",
      " > oh i guess\n",
      "Epoch[21/50] step:[1000/2110] loss:3.923163 took:0.46568s\n",
      "Epoch[21/50] step:[1200/2110] loss:3.960588 took:0.43827s\n",
      "Epoch[21/50] step:[1400/2110] loss:4.255205 took:0.46676s\n",
      "Epoch[21/50] step:[1600/2110] loss:4.115940 took:0.48779s\n",
      "Epoch[21/50] step:[1800/2110] loss:4.341226 took:0.41652s\n",
      "Query > happy birthday have a nice day\n",
      " > its a unk\n",
      " > its not a long time\n",
      " > its not a good idea\n",
      " > its a unk\n",
      " > i dont know\n",
      "Query > how was it going\n",
      " > it was a long time\n",
      " > it was a long time ago i was a kid\n",
      " > it was a long time ago\n",
      " > it was the unk\n",
      " > oh well i dont know\n",
      "Epoch[21/50] step:[2000/2110] loss:4.352390 took:0.45885s\n",
      "Epoch[21/50] averaged loss:4.166335 took:952.52487s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[22/50] step:[0/2110] loss:4.002068 took:0.57699s\n",
      "Epoch[22/50] step:[200/2110] loss:4.195957 took:0.46466s\n",
      "Epoch[22/50] step:[400/2110] loss:4.314370 took:0.49247s\n",
      "Epoch[22/50] step:[600/2110] loss:4.131666 took:0.42109s\n",
      "Epoch[22/50] step:[800/2110] loss:3.866224 took:0.42293s\n",
      "Query > happy birthday have a nice day\n",
      " > thank you sir\n",
      " > i think so\n",
      " > its a unk\n",
      " > thank you\n",
      " > i think so\n",
      "Query > how was it going\n",
      " > i dont know\n",
      " > i dont know\n",
      " > oh well i dont know what youre talking about\n",
      " > i dont know\n",
      " > it was the unk\n",
      "Epoch[22/50] step:[1000/2110] loss:4.172682 took:0.47720s\n",
      "Epoch[22/50] step:[1200/2110] loss:3.955792 took:0.44309s\n",
      "Epoch[22/50] step:[1400/2110] loss:3.994729 took:0.41166s\n",
      "Epoch[22/50] step:[1600/2110] loss:4.163272 took:0.41430s\n",
      "Epoch[22/50] step:[1800/2110] loss:3.997366 took:0.49319s\n",
      "Query > happy birthday have a nice day\n",
      " > its a good idea\n",
      " > you mean it is a unk\n",
      " > i dont know what youre talking about\n",
      " > i know its a good idea i know what you mean\n",
      " > its a unk\n",
      "Query > how was it going\n",
      " > i dont know\n",
      " > i dont know\n",
      " > it was a long time ago\n",
      " > it wasnt a long time\n",
      " > i dont know\n",
      "Epoch[22/50] step:[2000/2110] loss:4.112434 took:0.45912s\n",
      "Epoch[22/50] averaged loss:4.120299 took:950.84262s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[23/50] step:[0/2110] loss:4.287889 took:0.56027s\n",
      "Epoch[23/50] step:[200/2110] loss:4.218622 took:0.45655s\n",
      "Epoch[23/50] step:[400/2110] loss:3.979972 took:0.47879s\n",
      "Epoch[23/50] step:[600/2110] loss:4.284672 took:0.42527s\n",
      "Epoch[23/50] step:[800/2110] loss:3.823209 took:0.47390s\n",
      "Query > happy birthday have a nice day\n",
      " > its a unk\n",
      " > its a good idea\n",
      " > its a unk\n",
      " > thank you\n",
      " > thank you\n",
      "Query > how was it going\n",
      " > i dont know\n",
      " > it was a good time\n",
      " > it wasnt the unk\n",
      " > it was a long time\n",
      " > i dont know\n",
      "Epoch[23/50] step:[1000/2110] loss:4.088609 took:0.46058s\n",
      "Epoch[23/50] step:[1200/2110] loss:3.794859 took:0.45523s\n",
      "Epoch[23/50] step:[1400/2110] loss:4.007401 took:0.44493s\n",
      "Epoch[23/50] step:[1600/2110] loss:4.266354 took:0.48229s\n",
      "Epoch[23/50] step:[1800/2110] loss:3.950018 took:0.42584s\n",
      "Query > happy birthday have a nice day\n",
      " > i know\n",
      " > i know\n",
      " > i dont know\n",
      " > its not a long time\n",
      " > i know its not a good idea\n",
      "Query > how was it going\n",
      " > it was a long time ago\n",
      " > i was unk\n",
      " > it was the unk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > i dont know\n",
      " > i dont know\n",
      "Epoch[23/50] step:[2000/2110] loss:3.839619 took:0.42067s\n",
      "Epoch[23/50] averaged loss:4.073029 took:951.77955s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[24/50] step:[0/2110] loss:3.808164 took:0.53888s\n",
      "Epoch[24/50] step:[200/2110] loss:3.790416 took:0.44076s\n",
      "Epoch[24/50] step:[400/2110] loss:4.030349 took:0.44266s\n",
      "Epoch[24/50] step:[600/2110] loss:3.782204 took:0.46725s\n",
      "Epoch[24/50] step:[800/2110] loss:4.198504 took:0.45040s\n",
      "Query > happy birthday have a nice day\n",
      " > i dont think so\n",
      " > its a unk\n",
      " > thank you sir\n",
      " > thank you sir\n",
      " > its a good time\n",
      "Query > how was it going\n",
      " > not good\n",
      " > i dont know\n",
      " > i dont know\n",
      " > i dont know\n",
      " > i dont know\n",
      "Epoch[24/50] step:[1000/2110] loss:4.618804 took:0.45881s\n",
      "Epoch[24/50] step:[1200/2110] loss:3.994356 took:0.44412s\n",
      "Epoch[24/50] step:[1400/2110] loss:4.216904 took:0.42090s\n",
      "Epoch[24/50] step:[1600/2110] loss:4.257865 took:0.46488s\n",
      "Epoch[24/50] step:[1800/2110] loss:4.270931 took:0.44217s\n",
      "Query > happy birthday have a nice day\n",
      " > its not a good\n",
      " > its not a good\n",
      " > its not a good\n",
      " > i dont know what youre talking about\n",
      " > i dont know what to say\n",
      "Query > how was it going\n",
      " > it was a long time ago\n",
      " > i dont know\n",
      " > it was a long time ago\n",
      " > it was a good time\n",
      " > i dont know\n",
      "Epoch[24/50] step:[2000/2110] loss:3.669375 took:0.40066s\n",
      "Epoch[24/50] averaged loss:4.029698 took:950.66738s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[25/50] step:[0/2110] loss:4.092962 took:0.57704s\n",
      "Epoch[25/50] step:[200/2110] loss:3.812714 took:0.48700s\n",
      "Epoch[25/50] step:[400/2110] loss:4.018466 took:0.45706s\n",
      "Epoch[25/50] step:[600/2110] loss:4.131249 took:0.40623s\n",
      "Epoch[25/50] step:[800/2110] loss:4.076746 took:0.44257s\n",
      "Query > happy birthday have a nice day\n",
      " > i dont think so\n",
      " > thank you sir\n",
      " > i know\n",
      " > i dont know\n",
      " > thank you sir\n",
      "Query > how was it going\n",
      " > i was just thinking about the first thing i could get in here\n",
      " > not bad\n",
      " > i dont know\n",
      " > not good\n",
      " > it was good\n",
      "Epoch[25/50] step:[1000/2110] loss:3.828765 took:0.47672s\n",
      "Epoch[25/50] step:[1200/2110] loss:3.844899 took:0.50131s\n",
      "Epoch[25/50] step:[1400/2110] loss:3.852410 took:0.42549s\n",
      "Epoch[25/50] step:[1600/2110] loss:4.013654 took:0.48088s\n",
      "Epoch[25/50] step:[1800/2110] loss:4.081944 took:0.44149s\n",
      "Query > happy birthday have a nice day\n",
      " > its a good idea\n",
      " > i know its a lot of unk\n",
      " > its not a long time\n",
      " > thank you\n",
      " > thank you\n",
      "Query > how was it going\n",
      " > it was a long time ago\n",
      " > it was a long time\n",
      " > it was a long time\n",
      " > i was hoping you were a little unk\n",
      " > i dont know\n",
      "Epoch[25/50] step:[2000/2110] loss:4.151437 took:0.46587s\n",
      "Epoch[25/50] averaged loss:3.981236 took:951.18839s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[26/50] step:[0/2110] loss:3.841291 took:0.48212s\n",
      "Epoch[26/50] step:[200/2110] loss:4.117053 took:0.48365s\n",
      "Epoch[26/50] step:[400/2110] loss:3.988063 took:0.41253s\n",
      "Epoch[26/50] step:[600/2110] loss:3.954416 took:0.40806s\n",
      "Epoch[26/50] step:[800/2110] loss:4.259120 took:0.42943s\n",
      "Query > happy birthday have a nice day\n",
      " > i dont know\n",
      " > i know\n",
      " > thank you very much\n",
      " > i dont know what youre talking about\n",
      " > i know\n",
      "Query > how was it going\n",
      " > i dont know\n",
      " > it was a long time ago\n",
      " > it was a long time ago\n",
      " > it was the only one\n",
      " > it was a good time\n",
      "Epoch[26/50] step:[1000/2110] loss:3.651926 took:0.46304s\n",
      "Epoch[26/50] step:[1200/2110] loss:3.944790 took:0.45434s\n",
      "Epoch[26/50] step:[1400/2110] loss:3.916578 took:0.50318s\n",
      "Epoch[26/50] step:[1600/2110] loss:3.878495 took:0.46427s\n",
      "Epoch[26/50] step:[1800/2110] loss:3.865983 took:0.40224s\n",
      "Query > happy birthday have a nice day\n",
      " > thank you\n",
      " > i know\n",
      " > thank you\n",
      " > its not a long time\n",
      " > thank you\n",
      "Query > how was it going\n",
      " > it was a good time ago i was unk unk\n",
      " > it was the unk\n",
      " > it was the unk\n",
      " > it was a good time\n",
      " > it was a good time ago\n",
      "Epoch[26/50] step:[2000/2110] loss:3.929566 took:0.41890s\n",
      "Epoch[26/50] averaged loss:3.936362 took:951.52577s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[27/50] step:[0/2110] loss:3.748840 took:0.52748s\n",
      "Epoch[27/50] step:[200/2110] loss:3.882115 took:0.43368s\n",
      "Epoch[27/50] step:[400/2110] loss:3.734530 took:0.48694s\n",
      "Epoch[27/50] step:[600/2110] loss:3.495649 took:0.47764s\n",
      "Epoch[27/50] step:[800/2110] loss:3.838391 took:0.44100s\n",
      "Query > happy birthday have a nice day\n",
      " > thank you very much\n",
      " > thank you\n",
      " > thank you\n",
      " > thank you very much thank you\n",
      " > thank you\n",
      "Query > how was it going\n",
      " > i dont know\n",
      " > it was a long time ago\n",
      " > i was just thinking about you\n",
      " > it was a good time ago i was unk\n",
      " > it was a long time ago\n",
      "Epoch[27/50] step:[1000/2110] loss:3.750693 took:0.46910s\n",
      "Epoch[27/50] step:[1200/2110] loss:3.966501 took:0.46336s\n",
      "Epoch[27/50] step:[1400/2110] loss:3.863472 took:0.49608s\n",
      "Epoch[27/50] step:[1600/2110] loss:4.130793 took:0.48275s\n",
      "Epoch[27/50] step:[1800/2110] loss:4.071616 took:0.42403s\n",
      "Query > happy birthday have a nice day\n",
      " > i know\n",
      " > thank you very much\n",
      " > thank you very much\n",
      " > thank you very much\n",
      " > i know\n",
      "Query > how was it going\n",
      " > just a little unk\n",
      " > it was the only time to get out of the house\n",
      " > i dont know\n",
      " > it was a long time ago\n",
      " > i dont know\n",
      "Epoch[27/50] step:[2000/2110] loss:4.086059 took:0.43341s\n",
      "Epoch[27/50] averaged loss:3.891291 took:953.13013s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[28/50] step:[0/2110] loss:3.764435 took:0.56619s\n",
      "Epoch[28/50] step:[200/2110] loss:3.870061 took:0.42042s\n",
      "Epoch[28/50] step:[400/2110] loss:3.930978 took:0.49183s\n",
      "Epoch[28/50] step:[600/2110] loss:3.543154 took:0.48311s\n",
      "Epoch[28/50] step:[800/2110] loss:3.843539 took:0.42882s\n",
      "Query > happy birthday have a nice day\n",
      " > thank you\n",
      " > i know\n",
      " > thank you very much\n",
      " > thanks i know\n",
      " > thanks i know\n",
      "Query > how was it going\n",
      " > it was a unk\n",
      " > it was a long time ago i was unk\n",
      " > i dont know\n",
      " > i dont know\n",
      " > it was a unk\n",
      "Epoch[28/50] step:[1000/2110] loss:3.841482 took:0.40205s\n",
      "Epoch[28/50] step:[1200/2110] loss:3.676497 took:0.45571s\n",
      "Epoch[28/50] step:[1400/2110] loss:3.615985 took:0.44459s\n",
      "Epoch[28/50] step:[1600/2110] loss:3.647110 took:0.49159s\n",
      "Epoch[28/50] step:[1800/2110] loss:3.733564 took:0.48945s\n",
      "Query > happy birthday have a nice day\n",
      " > thank you\n",
      " > its a good idea\n",
      " > i know it was a great time but it was a unk\n",
      " > thank you\n",
      " > thank you\n",
      "Query > how was it going\n",
      " > i dont know i dont think so\n",
      " > i dont know\n",
      " > it was a long time ago\n",
      " > it was a long time ago i was unk\n",
      " > it was the only one\n",
      "Epoch[28/50] step:[2000/2110] loss:3.935740 took:0.43036s\n",
      "Epoch[28/50] averaged loss:3.842229 took:950.75549s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[29/50] step:[0/2110] loss:3.749010 took:0.52774s\n",
      "Epoch[29/50] step:[200/2110] loss:3.472870 took:0.41996s\n",
      "Epoch[29/50] step:[400/2110] loss:3.911657 took:0.47826s\n",
      "Epoch[29/50] step:[600/2110] loss:3.759507 took:0.44002s\n",
      "Epoch[29/50] step:[800/2110] loss:3.819503 took:0.49351s\n",
      "Query > happy birthday have a nice day\n",
      " > thank you very much\n",
      " > thank you\n",
      " > thank you very much thank you\n",
      " > thank you very much\n",
      " > i know\n",
      "Query > how was it going\n",
      " > it was a good time\n",
      " > it was a good time ago\n",
      " > it was the only time to get a little surprise\n",
      " > it was a good time ago\n",
      " > i dont know\n",
      "Epoch[29/50] step:[1000/2110] loss:4.297379 took:0.47734s\n",
      "Epoch[29/50] step:[1200/2110] loss:3.658673 took:0.39284s\n",
      "Epoch[29/50] step:[1400/2110] loss:3.833586 took:0.50231s\n",
      "Epoch[29/50] step:[1600/2110] loss:3.390469 took:0.38454s\n",
      "Epoch[29/50] step:[1800/2110] loss:4.171005 took:0.45453s\n",
      "Query > happy birthday have a nice day\n",
      " > thank you very much\n",
      " > thanks you know\n",
      " > thank you very much\n",
      " > i know\n",
      " > thank you\n",
      "Query > how was it going\n",
      " > it was a long time ago\n",
      " > it was the only time to get out\n",
      " > it wasnt the best time\n",
      " > just a little\n",
      " > i dont know i guess\n",
      "Epoch[29/50] step:[2000/2110] loss:3.852283 took:0.43287s\n",
      "Epoch[29/50] averaged loss:3.795596 took:949.85525s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[30/50] step:[0/2110] loss:3.831404 took:0.47641s\n",
      "Epoch[30/50] step:[200/2110] loss:3.820532 took:0.40071s\n",
      "Epoch[30/50] step:[400/2110] loss:3.447498 took:0.42726s\n",
      "Epoch[30/50] step:[600/2110] loss:3.736496 took:0.45298s\n",
      "Epoch[30/50] step:[800/2110] loss:3.642877 took:0.42205s\n",
      "Query > happy birthday have a nice day\n",
      " > i know it is\n",
      " > thank you\n",
      " > thanks you know i just dont know how to do that\n",
      " > thanks you mean\n",
      " > thank you very much\n",
      "Query > how was it going\n",
      " > i dont know\n",
      " > it was unk i was unk by the unk\n",
      " > just like it\n",
      " > i dont know\n",
      " > it was a long time ago\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[30/50] step:[1000/2110] loss:3.617737 took:0.41309s\n",
      "Epoch[30/50] step:[1200/2110] loss:3.753987 took:0.47275s\n",
      "Epoch[30/50] step:[1400/2110] loss:3.816749 took:0.44454s\n",
      "Epoch[30/50] step:[1600/2110] loss:4.106244 took:0.45165s\n",
      "Epoch[30/50] step:[1800/2110] loss:3.934877 took:0.44001s\n",
      "Query > happy birthday have a nice day\n",
      " > thank you\n",
      " > thanks you mean\n",
      " > i know\n",
      " > thank you very much\n",
      " > thank you\n",
      "Query > how was it going\n",
      " > it was unk i was unk\n",
      " > it was a long time\n",
      " > i dont know\n",
      " > it wasnt a long time ago\n",
      " > it was a long time ago\n",
      "Epoch[30/50] step:[2000/2110] loss:3.959654 took:0.45703s\n",
      "Epoch[30/50] averaged loss:3.749950 took:944.50406s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[31/50] step:[0/2110] loss:3.678099 took:0.53443s\n",
      "Epoch[31/50] step:[200/2110] loss:3.694261 took:0.43996s\n",
      "Epoch[31/50] step:[400/2110] loss:3.672427 took:0.46825s\n",
      "Epoch[31/50] step:[600/2110] loss:3.616123 took:0.42846s\n",
      "Epoch[31/50] step:[800/2110] loss:3.422000 took:0.45871s\n",
      "Query > happy birthday have a nice day\n",
      " > thank you\n",
      " > thanks i am\n",
      " > thank you\n",
      " > thank you very much\n",
      " > i know\n",
      "Query > how was it going\n",
      " > oh i dont know\n",
      " > it was a long time ago\n",
      " > it wasnt a long time ago\n",
      " > it was good\n",
      " > i dont know\n",
      "Epoch[31/50] step:[1000/2110] loss:3.505233 took:0.38674s\n",
      "Epoch[31/50] step:[1200/2110] loss:3.519206 took:0.45057s\n",
      "Epoch[31/50] step:[1400/2110] loss:3.459564 took:0.38344s\n",
      "Epoch[31/50] step:[1600/2110] loss:3.848178 took:0.44954s\n",
      "Epoch[31/50] step:[1800/2110] loss:3.842480 took:0.42269s\n",
      "Query > happy birthday have a nice day\n",
      " > thank you very much\n",
      " > thank you very much\n",
      " > thank you very much\n",
      " > thank you\n",
      " > i know you have to be unk\n",
      "Query > how was it going\n",
      " > it was a long time ago\n",
      " > i dont know\n",
      " > i dont know\n",
      " > it was a good time\n",
      " > i dont know i guess i just dont know\n",
      "Epoch[31/50] step:[2000/2110] loss:3.644560 took:0.46890s\n",
      "Epoch[31/50] averaged loss:3.702162 took:944.87855s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[32/50] step:[0/2110] loss:3.724862 took:0.55274s\n",
      "Epoch[32/50] step:[200/2110] loss:3.438355 took:0.42252s\n",
      "Epoch[32/50] step:[400/2110] loss:3.371171 took:0.47270s\n",
      "Epoch[32/50] step:[600/2110] loss:3.573910 took:0.48980s\n",
      "Epoch[32/50] step:[800/2110] loss:3.909822 took:0.41957s\n",
      "Query > happy birthday have a nice day\n",
      " > i think you are but a little unk\n",
      " > thank you very much\n",
      " > thank you\n",
      " > its a unk\n",
      " > thank you\n",
      "Query > how was it going\n",
      " > it was a long time ago\n",
      " > it was a long time ago\n",
      " > just a few days to see you at the unk\n",
      " > it was a unk\n",
      " > it was unk i was unk to see you\n",
      "Epoch[32/50] step:[1000/2110] loss:3.470036 took:0.37888s\n",
      "Epoch[32/50] step:[1200/2110] loss:3.829789 took:0.44180s\n",
      "Epoch[32/50] step:[1400/2110] loss:3.683769 took:0.44240s\n",
      "Epoch[32/50] step:[1600/2110] loss:3.664050 took:0.41325s\n",
      "Epoch[32/50] step:[1800/2110] loss:3.990993 took:0.45475s\n",
      "Query > happy birthday have a nice day\n",
      " > thank you very much\n",
      " > i know its a unk\n",
      " > i dont think so\n",
      " > thank you\n",
      " > thank you very much\n",
      "Query > how was it going\n",
      " > it was a good time to see you\n",
      " > it was a long time ago\n",
      " > it was the best time to do\n",
      " > i dont know\n",
      " > it was a long time\n",
      "Epoch[32/50] step:[2000/2110] loss:3.613390 took:0.45792s\n",
      "Epoch[32/50] averaged loss:3.656886 took:946.27204s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[33/50] step:[0/2110] loss:3.379538 took:0.54773s\n",
      "Epoch[33/50] step:[200/2110] loss:3.620942 took:0.47649s\n",
      "Epoch[33/50] step:[400/2110] loss:3.895085 took:0.45392s\n",
      "Epoch[33/50] step:[600/2110] loss:3.771184 took:0.45923s\n",
      "Epoch[33/50] step:[800/2110] loss:3.549345 took:0.45596s\n",
      "Query > happy birthday have a nice day\n",
      " > thank you sir\n",
      " > i know its a unk\n",
      " > thank you sir\n",
      " > thank you sir\n",
      " > thank you very much\n",
      "Query > how was it going\n",
      " > you know how many times have you been in love with the unk\n",
      " > you know it was a unk\n",
      " > it was a long time ago\n",
      " > it was a good time\n",
      " > it was a long time ago\n",
      "Epoch[33/50] step:[1000/2110] loss:3.526377 took:0.41626s\n",
      "Epoch[33/50] step:[1200/2110] loss:3.606474 took:0.46304s\n",
      "Epoch[33/50] step:[1400/2110] loss:3.480555 took:0.44984s\n",
      "Epoch[33/50] step:[1600/2110] loss:3.765541 took:0.41850s\n",
      "Epoch[33/50] step:[1800/2110] loss:3.644622 took:0.43881s\n",
      "Query > happy birthday have a nice day\n",
      " > thank you sir\n",
      " > thank you very much\n",
      " > i know it is\n",
      " > thank you sir\n",
      " > its not a long\n",
      "Query > how was it going\n",
      " > it was a long time\n",
      " > it was a long time\n",
      " > you know i was just thinking about you\n",
      " > it was a long time ago\n",
      " > it was a good time\n",
      "Epoch[33/50] step:[2000/2110] loss:3.625983 took:0.39677s\n",
      "Epoch[33/50] averaged loss:3.608860 took:947.94422s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[34/50] step:[0/2110] loss:3.537249 took:0.52266s\n",
      "Epoch[34/50] step:[200/2110] loss:3.260013 took:0.46952s\n",
      "Epoch[34/50] step:[400/2110] loss:3.425201 took:0.45061s\n",
      "Epoch[34/50] step:[600/2110] loss:3.720301 took:0.46234s\n",
      "Epoch[34/50] step:[800/2110] loss:3.796248 took:0.48580s\n",
      "Query > happy birthday have a nice day\n",
      " > its a unk\n",
      " > thank you very much\n",
      " > i know you are\n",
      " > thank you very much\n",
      " > i think you should be able to get a unk\n",
      "Query > how was it going\n",
      " > i dont know i dont know\n",
      " > it was a long time ago\n",
      " > it wasnt me i was unk\n",
      " > it was a long time ago\n",
      " > i dont know\n",
      "Epoch[34/50] step:[1000/2110] loss:3.247115 took:0.39276s\n",
      "Epoch[34/50] step:[1200/2110] loss:3.712049 took:0.40459s\n",
      "Epoch[34/50] step:[1400/2110] loss:3.126361 took:0.43869s\n",
      "Epoch[34/50] step:[1600/2110] loss:3.823262 took:0.48331s\n",
      "Epoch[34/50] step:[1800/2110] loss:3.446098 took:0.44317s\n",
      "Query > happy birthday have a nice day\n",
      " > i know it is\n",
      " > thank you very much thank you\n",
      " > thank you very much\n",
      " > i know it was a unk but i was just unk\n",
      " > thank you very much\n",
      "Query > how was it going\n",
      " > you know it was a great idea of mine i dont know what youre doing\n",
      " > i dont know\n",
      " > it was unk i was unk\n",
      " > it was a long time ago\n",
      " > it was a good time ago i was unk\n",
      "Epoch[34/50] step:[2000/2110] loss:3.911299 took:0.46059s\n",
      "Epoch[34/50] averaged loss:3.564556 took:944.49516s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[35/50] step:[0/2110] loss:3.556966 took:0.57539s\n",
      "Epoch[35/50] step:[200/2110] loss:3.318543 took:0.44128s\n",
      "Epoch[35/50] step:[400/2110] loss:3.511539 took:0.46982s\n",
      "Epoch[35/50] step:[600/2110] loss:3.520315 took:0.41293s\n",
      "Epoch[35/50] step:[800/2110] loss:3.772524 took:0.44159s\n",
      "Query > happy birthday have a nice day\n",
      " > thank you sir\n",
      " > i know\n",
      " > thank you\n",
      " > i dont know\n",
      " > thank you sir\n",
      "Query > how was it going\n",
      " > it was a long time ago\n",
      " > i dont know\n",
      " > it was a long time\n",
      " > it was a long time ago\n",
      " > i dont know\n",
      "Epoch[35/50] step:[1000/2110] loss:3.484487 took:0.46387s\n",
      "Epoch[35/50] step:[1200/2110] loss:3.536973 took:0.39956s\n",
      "Epoch[35/50] step:[1400/2110] loss:3.788132 took:0.41159s\n",
      "Epoch[35/50] step:[1600/2110] loss:3.515180 took:0.45065s\n",
      "Epoch[35/50] step:[1800/2110] loss:3.392599 took:0.45639s\n",
      "Query > happy birthday have a nice day\n",
      " > its a unk its a good idea\n",
      " > thank you very much thank you very much\n",
      " > thank you very much thank you\n",
      " > its not really\n",
      " > thank you very much\n",
      "Query > how was it going\n",
      " > i dont know\n",
      " > it wasnt unk\n",
      " > just like a little unk\n",
      " > i dont know\n",
      " > i dont know i guess i was just looking for a friend\n",
      "Epoch[35/50] step:[2000/2110] loss:3.619323 took:0.48079s\n",
      "Epoch[35/50] averaged loss:3.520070 took:944.66820s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[36/50] step:[0/2110] loss:3.329064 took:0.54494s\n",
      "Epoch[36/50] step:[200/2110] loss:3.263028 took:0.44230s\n",
      "Epoch[36/50] step:[400/2110] loss:3.466889 took:0.46263s\n",
      "Epoch[36/50] step:[600/2110] loss:3.462137 took:0.44420s\n",
      "Epoch[36/50] step:[800/2110] loss:3.757102 took:0.41801s\n",
      "Query > happy birthday have a nice day\n",
      " > i know its a good thing\n",
      " > thank you\n",
      " > thank you\n",
      " > its not a long time\n",
      " > i dont think so\n",
      "Query > how was it going\n",
      " > i dont know i guess\n",
      " > not good\n",
      " > not good\n",
      " > i dont know i guess\n",
      " > i dont know\n",
      "Epoch[36/50] step:[1000/2110] loss:3.259793 took:0.34319s\n",
      "Epoch[36/50] step:[1200/2110] loss:3.511890 took:0.38598s\n",
      "Epoch[36/50] step:[1400/2110] loss:3.416031 took:0.41926s\n",
      "Epoch[36/50] step:[1600/2110] loss:3.788007 took:0.42338s\n",
      "Epoch[36/50] step:[1800/2110] loss:3.549241 took:0.36564s\n",
      "Query > happy birthday have a nice day\n",
      " > thank you sir\n",
      " > thank you sir\n",
      " > i know you are but i know you have to be\n",
      " > thank you very much\n",
      " > its not a good\n",
      "Query > how was it going\n",
      " > it was a long time ago\n",
      " > it was good\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > just like a few minutes ago\n",
      " > it wasnt a long time\n",
      " > i dont know\n",
      "Epoch[36/50] step:[2000/2110] loss:3.336208 took:0.42671s\n",
      "Epoch[36/50] averaged loss:3.474585 took:944.01954s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[37/50] step:[0/2110] loss:3.512980 took:0.58408s\n",
      "Epoch[37/50] step:[200/2110] loss:3.484130 took:0.47610s\n",
      "Epoch[37/50] step:[400/2110] loss:3.520934 took:0.39605s\n",
      "Epoch[37/50] step:[600/2110] loss:3.365673 took:0.46666s\n",
      "Epoch[37/50] step:[800/2110] loss:3.429557 took:0.43754s\n",
      "Query > happy birthday have a nice day\n",
      " > its not a long\n",
      " > its not really\n",
      " > thank you sir\n",
      " > thank you sir\n",
      " > its a good idea\n",
      "Query > how was it going\n",
      " > not bad\n",
      " > it was the best time to see the unk\n",
      " > it was a long time ago\n",
      " > i dont know\n",
      " > it was a long time ago\n",
      "Epoch[37/50] step:[1000/2110] loss:3.224291 took:0.45601s\n",
      "Epoch[37/50] step:[1200/2110] loss:3.331098 took:0.42724s\n",
      "Epoch[37/50] step:[1400/2110] loss:3.509528 took:0.47373s\n",
      "Epoch[37/50] step:[1600/2110] loss:3.094489 took:0.47730s\n",
      "Epoch[37/50] step:[1800/2110] loss:3.384497 took:0.48630s\n",
      "Query > happy birthday have a nice day\n",
      " > thank you very much\n",
      " > its not a good\n",
      " > i dont know\n",
      " > thank you sir\n",
      " > i know you are but i know you are\n",
      "Query > how was it going\n",
      " > it was a long time ago\n",
      " > it was unk i was wondering\n",
      " > it was a long time ago\n",
      " > just a few minutes\n",
      " > i dont know\n",
      "Epoch[37/50] step:[2000/2110] loss:3.706235 took:0.42251s\n",
      "Epoch[37/50] averaged loss:3.428135 took:941.91844s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[38/50] step:[0/2110] loss:3.425380 took:0.45891s\n",
      "Epoch[38/50] step:[200/2110] loss:3.285495 took:0.46808s\n",
      "Epoch[38/50] step:[400/2110] loss:3.260036 took:0.42122s\n",
      "Epoch[38/50] step:[600/2110] loss:3.289839 took:0.47099s\n",
      "Epoch[38/50] step:[800/2110] loss:3.545812 took:0.47980s\n",
      "Query > happy birthday have a nice day\n",
      " > thank you very much\n",
      " > thank you\n",
      " > i dont know what youre talking about\n",
      " > thank you\n",
      " > thank you\n",
      "Query > how was it going\n",
      " > i dont know\n",
      " > it was a good time\n",
      " > i dont know\n",
      " > it was a good time\n",
      " > it was a long time ago\n",
      "Epoch[38/50] step:[1000/2110] loss:3.512362 took:0.46508s\n",
      "Epoch[38/50] step:[1200/2110] loss:3.457961 took:0.47501s\n",
      "Epoch[38/50] step:[1400/2110] loss:2.986069 took:0.38970s\n",
      "Epoch[38/50] step:[1600/2110] loss:3.432912 took:0.47920s\n",
      "Epoch[38/50] step:[1800/2110] loss:3.355375 took:0.47454s\n",
      "Query > happy birthday have a nice day\n",
      " > thank you\n",
      " > thank you very much thank you\n",
      " > thank you very much\n",
      " > thank you very much\n",
      " > i know you were a very good person\n",
      "Query > how was it going\n",
      " > i dont remember\n",
      " > i dont know\n",
      " > i dont know i guess i was just scared\n",
      " > it was unk\n",
      " > just a little good enough\n",
      "Epoch[38/50] step:[2000/2110] loss:3.220657 took:0.47765s\n",
      "Epoch[38/50] averaged loss:3.387936 took:943.91606s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[39/50] step:[0/2110] loss:3.526291 took:0.53598s\n",
      "Epoch[39/50] step:[200/2110] loss:3.411744 took:0.45283s\n",
      "Epoch[39/50] step:[400/2110] loss:3.350804 took:0.44053s\n",
      "Epoch[39/50] step:[600/2110] loss:3.424151 took:0.42966s\n",
      "Epoch[39/50] step:[800/2110] loss:3.334545 took:0.42179s\n",
      "Query > happy birthday have a nice day\n",
      " > its not me\n",
      " > thats it it was\n",
      " > thank you very much\n",
      " > thats all right\n",
      " > thats all right\n",
      "Query > how was it going\n",
      " > i dont know i guess i was just scared\n",
      " > it was a good time\n",
      " > just a little good\n",
      " > i dont know\n",
      " > just a little good to see you\n",
      "Epoch[39/50] step:[1000/2110] loss:3.269151 took:0.45074s\n",
      "Epoch[39/50] step:[1200/2110] loss:3.313649 took:0.45250s\n",
      "Epoch[39/50] step:[1400/2110] loss:3.506099 took:0.48755s\n",
      "Epoch[39/50] step:[1600/2110] loss:3.156176 took:0.46599s\n",
      "Epoch[39/50] step:[1800/2110] loss:3.378518 took:0.46337s\n",
      "Query > happy birthday have a nice day\n",
      " > thank you\n",
      " > thank you very much\n",
      " > thank you\n",
      " > thank you\n",
      " > thank you very much\n",
      "Query > how was it going\n",
      " > just like a little unk\n",
      " > just a little unk\n",
      " > it was a good time\n",
      " > it was a good time ago\n",
      " > it was a long time ago\n",
      "Epoch[39/50] step:[2000/2110] loss:3.183401 took:0.44439s\n",
      "Epoch[39/50] averaged loss:3.344578 took:943.14135s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[40/50] step:[0/2110] loss:3.169739 took:0.62043s\n",
      "Epoch[40/50] step:[200/2110] loss:3.368181 took:0.41070s\n",
      "Epoch[40/50] step:[400/2110] loss:3.273783 took:0.50154s\n",
      "Epoch[40/50] step:[600/2110] loss:3.497503 took:0.45290s\n",
      "Epoch[40/50] step:[800/2110] loss:3.217624 took:0.46258s\n",
      "Query > happy birthday have a nice day\n",
      " > thank you\n",
      " > its a good time\n",
      " > i am\n",
      " > thank you\n",
      " > its a good idea\n",
      "Query > how was it going\n",
      " > i dont know\n",
      " > it was a long time ago\n",
      " > it was good\n",
      " > i dont know\n",
      " > it was good\n",
      "Epoch[40/50] step:[1000/2110] loss:3.460429 took:0.46431s\n",
      "Epoch[40/50] step:[1200/2110] loss:3.311776 took:0.50364s\n",
      "Epoch[40/50] step:[1400/2110] loss:3.416135 took:0.43880s\n",
      "Epoch[40/50] step:[1600/2110] loss:3.239568 took:0.47818s\n",
      "Epoch[40/50] step:[1800/2110] loss:3.409420 took:0.40586s\n",
      "Query > happy birthday have a nice day\n",
      " > its not really\n",
      " > thank you very much\n",
      " > thank you very much\n",
      " > thank you very much\n",
      " > thank you\n",
      "Query > how was it going\n",
      " > i dont know\n",
      " > it was a good time\n",
      " > not good\n",
      " > i dont know\n",
      " > it was unk\n",
      "Epoch[40/50] step:[2000/2110] loss:3.407475 took:0.37244s\n",
      "Epoch[40/50] averaged loss:3.300457 took:942.86174s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[41/50] step:[0/2110] loss:3.094264 took:0.59013s\n",
      "Epoch[41/50] step:[200/2110] loss:3.433199 took:0.45351s\n",
      "Epoch[41/50] step:[400/2110] loss:3.247822 took:0.45043s\n",
      "Epoch[41/50] step:[600/2110] loss:3.259716 took:0.48219s\n",
      "Epoch[41/50] step:[800/2110] loss:3.429607 took:0.46088s\n",
      "Query > happy birthday have a nice day\n",
      " > i dont know what to say\n",
      " > thank you very much\n",
      " > thank you sir\n",
      " > thank you very much\n",
      " > thank you very much\n",
      "Query > how was it going\n",
      " > i dont know\n",
      " > it was a good time to meet you\n",
      " > i was unk by the unk\n",
      " > it was a long time ago\n",
      " > i dont know\n",
      "Epoch[41/50] step:[1000/2110] loss:3.523394 took:0.49498s\n",
      "Epoch[41/50] step:[1200/2110] loss:3.259258 took:0.48713s\n",
      "Epoch[41/50] step:[1400/2110] loss:3.231774 took:0.46440s\n",
      "Epoch[41/50] step:[1600/2110] loss:3.160377 took:0.48964s\n",
      "Epoch[41/50] step:[1800/2110] loss:3.131161 took:0.48491s\n",
      "Query > happy birthday have a nice day\n",
      " > thank you\n",
      " > thank you\n",
      " > thank you\n",
      " > thank you\n",
      " > thank you\n",
      "Query > how was it going\n",
      " > i dont know i guess\n",
      " > i dont know\n",
      " > i dont remember\n",
      " > i dont know\n",
      " > it was unk\n",
      "Epoch[41/50] step:[2000/2110] loss:3.354398 took:0.38232s\n",
      "Epoch[41/50] averaged loss:3.256492 took:943.97074s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[42/50] step:[0/2110] loss:3.397043 took:0.55855s\n",
      "Epoch[42/50] step:[200/2110] loss:2.860961 took:0.39327s\n",
      "Epoch[42/50] step:[400/2110] loss:3.112380 took:0.41191s\n",
      "Epoch[42/50] step:[600/2110] loss:3.091146 took:0.42721s\n",
      "Epoch[42/50] step:[800/2110] loss:3.398214 took:0.44985s\n",
      "Query > happy birthday have a nice day\n",
      " > i dont know how much i can do\n",
      " > its a unk\n",
      " > thank you\n",
      " > thank you very much\n",
      " > thank you\n",
      "Query > how was it going\n",
      " > it was unk i was wondering how much i feel\n",
      " > it was a good time\n",
      " > i dont know\n",
      " > it was unk\n",
      " > just a little less\n",
      "Epoch[42/50] step:[1000/2110] loss:3.152311 took:0.45632s\n",
      "Epoch[42/50] step:[1200/2110] loss:3.053207 took:0.46096s\n",
      "Epoch[42/50] step:[1400/2110] loss:3.146776 took:0.45753s\n",
      "Epoch[42/50] step:[1600/2110] loss:3.225104 took:0.44607s\n",
      "Epoch[42/50] step:[1800/2110] loss:3.419891 took:0.46068s\n",
      "Query > happy birthday have a nice day\n",
      " > thank you very much\n",
      " > thank you very much thank you\n",
      " > thank you very much\n",
      " > thank you very much\n",
      " > i dont think so\n",
      "Query > how was it going\n",
      " > not good but i dont know what to say\n",
      " > i dont know\n",
      " > it was the best time i was in the unk\n",
      " > it was a long time ago\n",
      " > it was a good time to unk the unk\n",
      "Epoch[42/50] step:[2000/2110] loss:3.205426 took:0.45672s\n",
      "Epoch[42/50] averaged loss:3.215699 took:945.02051s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[43/50] step:[0/2110] loss:3.092360 took:0.57807s\n",
      "Epoch[43/50] step:[200/2110] loss:3.164088 took:0.42156s\n",
      "Epoch[43/50] step:[400/2110] loss:3.257647 took:0.43791s\n",
      "Epoch[43/50] step:[600/2110] loss:3.387182 took:0.37689s\n",
      "Epoch[43/50] step:[800/2110] loss:3.329473 took:0.42774s\n",
      "Query > happy birthday have a nice day\n",
      " > i am\n",
      " > i am\n",
      " > i am i am\n",
      " > its a good idea\n",
      " > thank you\n",
      "Query > how was it going\n",
      " > just like you said i was going to be a little unk i dont know what to say\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > i was hoping you were in the bathroom\n",
      " > just a little unk and a half\n",
      " > just a little unk\n",
      " > it was a long time ago\n",
      "Epoch[43/50] step:[1000/2110] loss:2.785696 took:0.38547s\n",
      "Epoch[43/50] step:[1200/2110] loss:3.376303 took:0.45661s\n",
      "Epoch[43/50] step:[1400/2110] loss:3.296626 took:0.46909s\n",
      "Epoch[43/50] step:[1600/2110] loss:3.329867 took:0.45078s\n",
      "Epoch[43/50] step:[1800/2110] loss:2.984496 took:0.34620s\n",
      "Query > happy birthday have a nice day\n",
      " > thank you very much\n",
      " > thank you\n",
      " > its not really\n",
      " > its a good night\n",
      " > thank you very much\n",
      "Query > how was it going\n",
      " > i dont know\n",
      " > it was a good time\n",
      " > it was a long time ago\n",
      " > i dont know\n",
      " > i dont know\n",
      "Epoch[43/50] step:[2000/2110] loss:3.426354 took:0.46537s\n",
      "Epoch[43/50] averaged loss:3.172437 took:945.47296s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[44/50] step:[0/2110] loss:3.156771 took:0.58777s\n",
      "Epoch[44/50] step:[200/2110] loss:2.989133 took:0.43573s\n",
      "Epoch[44/50] step:[400/2110] loss:3.441839 took:0.46443s\n",
      "Epoch[44/50] step:[600/2110] loss:2.952097 took:0.42322s\n",
      "Epoch[44/50] step:[800/2110] loss:3.007724 took:0.46750s\n",
      "Query > happy birthday have a nice day\n",
      " > thank you sir\n",
      " > i am\n",
      " > thank you very much\n",
      " > thank you sir\n",
      " > thank you very much\n",
      "Query > how was it going\n",
      " > it was a good time ago\n",
      " > i was unk\n",
      " > you know how many times have been been in\n",
      " > i dont know i just got a little unk in my office\n",
      " > i dont know i guess i was just sure\n",
      "Epoch[44/50] step:[1000/2110] loss:3.060314 took:0.42534s\n",
      "Epoch[44/50] step:[1200/2110] loss:3.084158 took:0.45093s\n",
      "Epoch[44/50] step:[1400/2110] loss:3.165336 took:0.39531s\n",
      "Epoch[44/50] step:[1600/2110] loss:3.148857 took:0.48136s\n",
      "Epoch[44/50] step:[1800/2110] loss:2.925809 took:0.44007s\n",
      "Query > happy birthday have a nice day\n",
      " > thank you very much\n",
      " > thank you very much\n",
      " > thank you\n",
      " > thank you\n",
      " > thank you\n",
      "Query > how was it going\n",
      " > just a little more\n",
      " > just a little less less\n",
      " > i dont know\n",
      " > it was a long time\n",
      " > it was a good time ago\n",
      "Epoch[44/50] step:[2000/2110] loss:3.058163 took:0.44511s\n",
      "Epoch[44/50] averaged loss:3.130624 took:944.08147s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[45/50] step:[0/2110] loss:3.059548 took:0.55122s\n",
      "Epoch[45/50] step:[200/2110] loss:3.202479 took:0.38889s\n",
      "Epoch[45/50] step:[400/2110] loss:2.864605 took:0.40030s\n",
      "Epoch[45/50] step:[600/2110] loss:2.832454 took:0.44321s\n",
      "Epoch[45/50] step:[800/2110] loss:3.294264 took:0.44322s\n",
      "Query > happy birthday have a nice day\n",
      " > its not really\n",
      " > thank you very much\n",
      " > thank you very much\n",
      " > thank you\n",
      " > thank you\n",
      "Query > how was it going\n",
      " > it was a long time ago\n",
      " > i dont know\n",
      " > just a little less enough to see\n",
      " > it was good\n",
      " > it was a long time ago\n",
      "Epoch[45/50] step:[1000/2110] loss:3.047924 took:0.44629s\n",
      "Epoch[45/50] step:[1200/2110] loss:3.137330 took:0.46172s\n",
      "Epoch[45/50] step:[1400/2110] loss:3.115309 took:0.46406s\n",
      "Epoch[45/50] step:[1600/2110] loss:2.878586 took:0.39355s\n",
      "Epoch[45/50] step:[1800/2110] loss:2.917202 took:0.46231s\n",
      "Query > happy birthday have a nice day\n",
      " > thank you\n",
      " > thank you very much\n",
      " > thank you\n",
      " > thank you\n",
      " > thank you very much\n",
      "Query > how was it going\n",
      " > it was a good time to see you\n",
      " > i dont know\n",
      " > i dont know\n",
      " > it was a good time to meet you\n",
      " > just let me see you\n",
      "Epoch[45/50] step:[2000/2110] loss:3.264820 took:0.42882s\n",
      "Epoch[45/50] averaged loss:3.089775 took:944.50409s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[46/50] step:[0/2110] loss:3.114178 took:0.52797s\n",
      "Epoch[46/50] step:[200/2110] loss:3.048594 took:0.48081s\n",
      "Epoch[46/50] step:[400/2110] loss:3.067037 took:0.44328s\n",
      "Epoch[46/50] step:[600/2110] loss:2.897878 took:0.35970s\n",
      "Epoch[46/50] step:[800/2110] loss:3.245555 took:0.40223s\n",
      "Query > happy birthday have a nice day\n",
      " > i dont think so\n",
      " > thank you sir\n",
      " > thank you very much\n",
      " > thank you very much\n",
      " > its not me\n",
      "Query > how was it going\n",
      " > i dont know\n",
      " > i dont remember\n",
      " > oh i dont know\n",
      " > it was a good time ago\n",
      " > oh i dont know\n",
      "Epoch[46/50] step:[1000/2110] loss:3.118843 took:0.42343s\n",
      "Epoch[46/50] step:[1200/2110] loss:2.887239 took:0.49904s\n",
      "Epoch[46/50] step:[1400/2110] loss:2.929173 took:0.43790s\n",
      "Epoch[46/50] step:[1600/2110] loss:3.012978 took:0.43257s\n",
      "Epoch[46/50] step:[1800/2110] loss:3.238350 took:0.48124s\n",
      "Query > happy birthday have a nice day\n",
      " > thank you sir\n",
      " > thank you sir\n",
      " > thank you sir\n",
      " > i think you should have been a bit unk unk\n",
      " > its not really its a good time\n",
      "Query > how was it going\n",
      " > it was a long time ago\n",
      " > it was a long time ago\n",
      " > i dont know\n",
      " > oh i guess\n",
      " > it was a good time\n",
      "Epoch[46/50] step:[2000/2110] loss:2.809614 took:0.47570s\n",
      "Epoch[46/50] averaged loss:3.049440 took:944.94303s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[47/50] step:[0/2110] loss:2.640688 took:0.54454s\n",
      "Epoch[47/50] step:[200/2110] loss:2.802457 took:0.42979s\n",
      "Epoch[47/50] step:[400/2110] loss:2.881758 took:0.45519s\n",
      "Epoch[47/50] step:[600/2110] loss:3.156245 took:0.43752s\n",
      "Epoch[47/50] step:[800/2110] loss:3.037404 took:0.42327s\n",
      "Query > happy birthday have a nice day\n",
      " > its not a good\n",
      " > its not really i know its just unk\n",
      " > thank you very much\n",
      " > its a good night\n",
      " > i am\n",
      "Query > how was it going\n",
      " > i dont know\n",
      " > just like a little while i can get it\n",
      " > it was a good time to meet you\n",
      " > it was a good time to meet you\n",
      " > it was a long time ago\n",
      "Epoch[47/50] step:[1000/2110] loss:3.113439 took:0.40400s\n",
      "Epoch[47/50] step:[1200/2110] loss:3.053942 took:0.44638s\n",
      "Epoch[47/50] step:[1400/2110] loss:3.106511 took:0.47758s\n",
      "Epoch[47/50] step:[1600/2110] loss:3.245288 took:0.43378s\n",
      "Epoch[47/50] step:[1800/2110] loss:2.678652 took:0.43364s\n",
      "Query > happy birthday have a nice day\n",
      " > i am\n",
      " > thank you\n",
      " > thank you very much\n",
      " > thank you very much\n",
      " > thank you very much\n",
      "Query > how was it going\n",
      " > it was a good time to meet you\n",
      " > it was a long time ago\n",
      " > i dont know\n",
      " > it was a good time to meet you\n",
      " > i dont know\n",
      "Epoch[47/50] step:[2000/2110] loss:3.277112 took:0.46619s\n",
      "Epoch[47/50] averaged loss:3.011761 took:945.32385s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[48/50] step:[0/2110] loss:2.925717 took:0.58742s\n",
      "Epoch[48/50] step:[200/2110] loss:2.771939 took:0.46161s\n",
      "Epoch[48/50] step:[400/2110] loss:2.965521 took:0.48236s\n",
      "Epoch[48/50] step:[600/2110] loss:2.695964 took:0.40169s\n",
      "Epoch[48/50] step:[800/2110] loss:2.837953 took:0.46286s\n",
      "Query > happy birthday have a nice day\n",
      " > i am very much thank you very much\n",
      " > thank you very much\n",
      " > thank you very much\n",
      " > thank you very much\n",
      " > i think you should have seen it\n",
      "Query > how was it going\n",
      " > oh i dont know\n",
      " > i dont know\n",
      " > it could be a long time to meet the unk\n",
      " > it was a long time ago\n",
      " > i dont know i guess\n",
      "Epoch[48/50] step:[1000/2110] loss:2.969867 took:0.37770s\n",
      "Epoch[48/50] step:[1200/2110] loss:2.935589 took:0.45250s\n",
      "Epoch[48/50] step:[1400/2110] loss:2.944516 took:0.47026s\n",
      "Epoch[48/50] step:[1600/2110] loss:2.850627 took:0.45971s\n",
      "Epoch[48/50] step:[1800/2110] loss:2.933095 took:0.43640s\n",
      "Query > happy birthday have a nice day\n",
      " > its not really i know\n",
      " > thank you sir\n",
      " > thank you very much\n",
      " > thank you very much\n",
      " > thank ya very much\n",
      "Query > how was it going\n",
      " > i dont know\n",
      " > it was a long time ago\n",
      " > it was a long time ago\n",
      " > oh i dont know\n",
      " > i dont know\n",
      "Epoch[48/50] step:[2000/2110] loss:2.983588 took:0.44668s\n",
      "Epoch[48/50] averaged loss:2.977324 took:944.98572s\n",
      "[TL] [*] n.npz saved\n",
      "Epoch[49/50] step:[0/2110] loss:2.909147 took:0.52519s\n",
      "Epoch[49/50] step:[200/2110] loss:2.811623 took:0.40097s\n",
      "Epoch[49/50] step:[400/2110] loss:2.774543 took:0.47148s\n",
      "Epoch[49/50] step:[600/2110] loss:2.682957 took:0.47577s\n",
      "Epoch[49/50] step:[800/2110] loss:2.882158 took:0.45314s\n",
      "Query > happy birthday have a nice day\n",
      " > thank ya\n",
      " > thank you very much\n",
      " > thank you very much\n",
      " > thank you\n",
      " > thank you\n",
      "Query > how was it going\n",
      " > i dont know\n",
      " > i dont know i just got a little more time\n",
      " > it was a long time ago\n",
      " > it was a long time ago\n",
      " > i was unk i was wondering how could i come in\n",
      "Epoch[49/50] step:[1000/2110] loss:2.616689 took:0.37264s\n",
      "Epoch[49/50] step:[1200/2110] loss:2.659165 took:0.40418s\n",
      "Epoch[49/50] step:[1400/2110] loss:3.155941 took:0.50009s\n",
      "Epoch[49/50] step:[1600/2110] loss:2.894798 took:0.38226s\n",
      "Epoch[49/50] step:[1800/2110] loss:3.178497 took:0.46878s\n",
      "Query > happy birthday have a nice day\n",
      " > its a good time\n",
      " > thank you very much\n",
      " > thank you\n",
      " > thank you\n",
      " > thank you\n",
      "Query > how was it going\n",
      " > i dont know i guess i got it\n",
      " > it was a good time ago\n",
      " > oh i dont know\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > i dont know\n",
      " > it was a long time ago\n",
      "Epoch[49/50] step:[2000/2110] loss:2.651119 took:0.47361s\n",
      "Epoch[49/50] averaged loss:2.932557 took:944.52380s\n",
      "[TL] [*] n.npz saved\n"
     ]
    }
   ],
   "source": [
    "###============= model\n",
    "def model(encode_seqs, decode_seqs, is_train=True, reuse=False):\n",
    "    with tf.variable_scope(\"model\", reuse=reuse):\n",
    "        # for chatbot, you can use the same embedding layer,\n",
    "        # for translation, you may want to use 2 seperated embedding layers\n",
    "        with tf.variable_scope(\"embedding\") as vs:\n",
    "            net_encode = EmbeddingInputlayer(\n",
    "                inputs = encode_seqs,\n",
    "                vocabulary_size = xvocab_size,\n",
    "                embedding_size = emb_dim,\n",
    "                name = 'seq_embedding')\n",
    "            vs.reuse_variables()\n",
    "            tl.layers.set_name_reuse(True) # remove if TL version == 1.8.0+\n",
    "            net_decode = EmbeddingInputlayer(\n",
    "                inputs = decode_seqs,\n",
    "                vocabulary_size = xvocab_size,\n",
    "                embedding_size = emb_dim,\n",
    "                name = 'seq_embedding')\n",
    "        net_rnn = Seq2Seq(net_encode, net_decode,\n",
    "                cell_fn = tf.contrib.rnn.BasicLSTMCell,\n",
    "                n_hidden = emb_dim,\n",
    "                initializer = tf.random_uniform_initializer(-0.1, 0.1),\n",
    "                encode_sequence_length = retrieve_seq_length_op2(encode_seqs),\n",
    "                decode_sequence_length = retrieve_seq_length_op2(decode_seqs),\n",
    "                initial_state_encode = None,\n",
    "                dropout = (0.5 if is_train else None),\n",
    "                n_layer = 3,\n",
    "                return_seq_2d = True,\n",
    "                name = 'seq2seq')\n",
    "        net_out = DenseLayer(net_rnn, n_units=xvocab_size, act=tf.identity, name='output')\n",
    "    return net_out, net_rnn\n",
    "\n",
    "# model for training\n",
    "with tf.device('/device:GPU:0'):\n",
    "    encode_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"encode_seqs\")\n",
    "    decode_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"decode_seqs\")\n",
    "    target_seqs = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"target_seqs\")\n",
    "    target_mask = tf.placeholder(dtype=tf.int64, shape=[batch_size, None], name=\"target_mask\") # tl.prepro.sequences_get_mask()\n",
    "net_out, _ = model(encode_seqs, decode_seqs, is_train=True, reuse=False)\n",
    "\n",
    "# model for inferencing\n",
    "with tf.device('/device:GPU:0'):\n",
    "    encode_seqs2 = tf.placeholder(dtype=tf.int64, shape=[1, None], name=\"encode_seqs\")\n",
    "    decode_seqs2 = tf.placeholder(dtype=tf.int64, shape=[1, None], name=\"decode_seqs\")\n",
    "net, net_rnn = model(encode_seqs2, decode_seqs2, is_train=False, reuse=True)\n",
    "y = tf.nn.softmax(net.outputs)\n",
    "\n",
    "loss = tl.cost.cross_entropy_seq_with_mask(logits=net_out.outputs, target_seqs=target_seqs, input_mask=target_mask, return_details=False, name='cost')\n",
    "\n",
    "net_out.print_params(False)\n",
    "\n",
    "lr = 0.0001\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=lr).minimize(loss)\n",
    "\n",
    "sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True))\n",
    "tl.layers.initialize_global_variables(sess)\n",
    "tl.files.load_and_assign_npz(sess=sess, name='n.npz', network=net)\n",
    "\n",
    "###============= train\n",
    "n_epoch = 50\n",
    "for epoch in range(n_epoch):\n",
    "    epoch_time = time.time()\n",
    "    ## shuffle training data\n",
    "    from sklearn.utils import shuffle\n",
    "    trainX, trainY = shuffle(trainX, trainY, random_state=0)\n",
    "    ## train an epoch\n",
    "    total_err, n_iter = 0, 0\n",
    "    for X, Y in tl.iterate.minibatches(inputs=trainX, targets=trainY, batch_size=batch_size, shuffle=False):\n",
    "        step_time = time.time()\n",
    "\n",
    "        X = tl.prepro.pad_sequences(X)\n",
    "        _target_seqs = tl.prepro.sequences_add_end_id(Y, end_id=end_id)\n",
    "        _target_seqs = tl.prepro.pad_sequences(_target_seqs)\n",
    "\n",
    "        _decode_seqs = tl.prepro.sequences_add_start_id(Y, start_id=start_id, remove_last=False)\n",
    "        _decode_seqs = tl.prepro.pad_sequences(_decode_seqs)\n",
    "        _target_mask = tl.prepro.sequences_get_mask(_target_seqs)\n",
    "\n",
    "        _, err = sess.run([train_op, loss],\n",
    "                        {encode_seqs: X,\n",
    "                        decode_seqs: _decode_seqs,\n",
    "                        target_seqs: _target_seqs,\n",
    "                        target_mask: _target_mask})\n",
    "\n",
    "        if n_iter % 200 == 0:\n",
    "            print(\"Epoch[%d/%d] step:[%d/%d] loss:%f took:%.5fs\" % (epoch, n_epoch, n_iter, n_step, err, time.time() - step_time))\n",
    "\n",
    "        total_err += err; n_iter += 1\n",
    "\n",
    "        ###============= inference\n",
    "        if n_iter % 1000 == 0:\n",
    "            seeds = [\"happy birthday have a nice day\",\n",
    "                    \"how was it going\"]\n",
    "            for seed in seeds:\n",
    "                print(\"Query >\", seed)\n",
    "                seed_id = [w2idx[w] for w in seed.split(\" \")]\n",
    "                for _ in range(5):  # 1 Query --> 5 Reply\n",
    "                    # 1. encode, get state\n",
    "                    state = sess.run(net_rnn.final_state_encode,\n",
    "                                    {encode_seqs2: [seed_id]})\n",
    "                    # 2. decode, feed start_id, get first word\n",
    "                    #   ref https://github.com/zsdonghao/tensorlayer/blob/master/example/tutorial_ptb_lstm_state_is_tuple.py\n",
    "                    o, state = sess.run([y, net_rnn.final_state_decode],\n",
    "                                    {net_rnn.initial_state_decode: state,\n",
    "                                    decode_seqs2: [[start_id]]})\n",
    "                    w_id = tl.nlp.sample_top(o[0], top_k=3)\n",
    "                    w = idx2w[w_id]\n",
    "                    # 3. decode, feed state iteratively\n",
    "                    sentence = [w]\n",
    "                    for _ in range(30): # max sentence length\n",
    "                        o, state = sess.run([y, net_rnn.final_state_decode],\n",
    "                                        {net_rnn.initial_state_decode: state,\n",
    "                                        decode_seqs2: [[w_id]]})\n",
    "                        w_id = tl.nlp.sample_top(o[0], top_k=2)\n",
    "                        w = idx2w[w_id]\n",
    "                        if w_id == end_id:\n",
    "                            break\n",
    "                        sentence = sentence + [w]\n",
    "                    print(\" >\", ' '.join(sentence))\n",
    "\n",
    "    print(\"Epoch[%d/%d] averaged loss:%f took:%.5fs\" % (epoch, n_epoch, total_err/n_iter, time.time()-epoch_time))\n",
    "\n",
    "    tl.files.save_npz(net.all_params, name='n.npz', sess=sess)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
